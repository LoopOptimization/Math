module;
#include "LoopMacros.hxx"
#include "Macros.hxx"
#ifdef __x86_64__
#include <immintrin.h>
#endif
#include <boost/container_hash/hash.hpp>
#include <boost/unordered/unordered_flat_map.hpp>
#include <boost/unordered/unordered_flat_set.hpp>

export module SIMD;

import Allocator;
import AxisTypes;
import BaseUtils;
import std;

export namespace boost {
using ::boost::hash;
using ::boost::hash_combine;
using ::boost::unordered_flat_map;
using ::boost::unordered_flat_set;

template <typename K>
using set = boost::unordered_flat_set<K, boost::hash<K>, std::equal_to<K>,
                                      alloc::Mallocator<K>>;
template <typename K, typename V>
using map = boost::unordered_flat_map<K, V, boost::hash<K>, std::equal_to<K>,
                                      alloc::Mallocator<std::pair<const K, V>>>;

} // namespace boost

// template <std::ptrdiff_t W, typename T>
// using Vec_ [[gnu::vector_size(W * sizeof(T))]] = T;

// template <std::ptrdiff_t W, typename T>
// using Vec_ = T [[clang::ext_vector_type(W)]];

export namespace simd {

template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N, typename T>
struct Unroll;

template <std::ptrdiff_t W, typename T>
using Vec = T [[clang::ext_vector_type(W)]];
template <std::ptrdiff_t W, typename T>
using El = std::conditional_t<W == 1, T, Vec<W, T>>;
#ifdef __x86_64__
#ifdef __AVX512F__
inline constexpr std::ptrdiff_t REGISTERS = 32;
inline constexpr std::ptrdiff_t VECTORWIDTH = 64;
#else // not __AVX512F__
inline constexpr std::ptrdiff_t REGISTERS = 16;
#ifdef __AVX__
inline constexpr std::ptrdiff_t VECTORWIDTH = 32;
#else  // no AVX
inline constexpr std::ptrdiff_t VECTORWIDTH = 16;
#endif // no AVX
#endif
#else  // not __x86_64__
inline constexpr std::ptrdiff_t REGISTERS = 32;
inline constexpr std::ptrdiff_t VECTORWIDTH = 16;
#endif // __x86_64__
template <std::ptrdiff_t W,
          typename I = std::conditional_t<W == 2, std::int64_t, std::int32_t>>
consteval auto range() -> Vec<W, I> {
  static_assert(std::popcount(std::size_t(W)) == 1);
  if constexpr (W == 2) return Vec<W, I>{0, 1};
  else if constexpr (W == 4) return Vec<W, I>{0, 1, 2, 3};
  else if constexpr (W == 8) return Vec<W, I>{0, 1, 2, 3, 4, 5, 6, 7};
  else if constexpr (W == 16)
    return Vec<W, I>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15};
  else {
    Vec<W, I> r;
    for (std::ptrdiff_t w = 0; w < W; ++w) r[w] = I(w);
    return r;
  }
}
template <std::ptrdiff_t W, typename T>
[[nodiscard]] TRIVIAL constexpr auto split(Vec<W, T> vec)
  -> std::array<El<W / 2Z, T>, 2>
  requires(W == 2 || W == 4 || W == 8 || W == 16) {
  if constexpr (W == 16) {
    return {__builtin_shufflevector(vec, vec, 0, 1, 2, 3, 4, 5, 6, 7),
            __builtin_shufflevector(vec, vec, 8, 9, 10, 11, 12, 13, 14, 15)};
  } else if constexpr (W == 8) {
    return {__builtin_shufflevector(vec, vec, 0, 1, 2, 3),
            __builtin_shufflevector(vec, vec, 4, 5, 6, 7)};
  } else if constexpr (W == 4) {
    return {__builtin_shufflevector(vec, vec, 0, 1),
            __builtin_shufflevector(vec, vec, 2, 3)};
  } else if constexpr (W == 2) {
    return {vec[0], vec[1]};
  } else static_assert("currently only supports W in {2,4,8,16}");
}

namespace mask {
/// Treats all elements as unmasked
template <std::ptrdiff_t W> struct None {
  TRIVIAL static constexpr auto onBegin() -> std::ptrdiff_t { return 0; }
  /// Values >= W indicate full masks
  TRIVIAL static constexpr auto onEnd() -> std::ptrdiff_t { return W; }
  TRIVIAL static constexpr auto offBegin() -> std::ptrdiff_t { return W; }
  TRIVIAL static constexpr auto offEnd() -> std::ptrdiff_t { return 0; }
};

// Alternatives we can have: BitMask and VectorMask
// We use `BitMask` on AVX512, VectorMask elsewhere.
// ARM SVE(2) will eventually want bitmasks as well.
#ifdef __x86_64__
#ifdef __AVX512F__
template <std::ptrdiff_t W> struct Bit {
  std::uint64_t mask_;
  // template <std::unsigned_integral U> TRIVIAL explicit constexpr operator U()
  // {
  //   return U(mask_);
  // }
  TRIVIAL [[nodiscard]] constexpr auto any() const -> bool { return mask_; }
  /// Returns the first `idx` where the mask bit is `0`
  TRIVIAL [[nodiscard]] constexpr auto onBegin() const -> std::ptrdiff_t {
    return std::ptrdiff_t(std::countr_zero(mask_));
  }
  TRIVIAL [[nodiscard]] constexpr auto popcount() const -> int {
    return std::popcount(mask_);
  }
  /// Returns the last `idx` where the mask bit is `1`
  /// Values >= W indicate full masks
  TRIVIAL [[nodiscard]] constexpr auto onEnd() const -> std::ptrdiff_t {
    if constexpr (W < 64z) {
      // could make this `countr_ones` if we decide to only
      // support leading masks
      std::uint64_t m = mask_ & ((1UL << W) - 1UL);
      return 64z - std::ptrdiff_t(std::countl_zero(m));
    } else return 64z - std::ptrdiff_t(std::countl_zero(mask_));
  }
  /// Returns the first `idx` where the mask bit is `0`
  TRIVIAL [[nodiscard]] constexpr auto offBegin() const -> std::ptrdiff_t {
    return std::ptrdiff_t(std::countr_one(mask_));
  }
  /// Returns the last `idx` where the mask bit is `0`
  TRIVIAL [[nodiscard]] constexpr auto offEnd() const -> std::ptrdiff_t {
    if constexpr (W < 64z) {
      std::uint64_t m = (~mask_) & ((1UL << W) - 1UL);
      return 64z - std::ptrdiff_t(std::countl_zero(m));
    } else return 64z - std::ptrdiff_t(std::countl_one(mask_));
  }
  template <std::ptrdiff_t S>
  TRIVIAL [[nodiscard]] constexpr auto sub() -> Bit<S> {
    static_assert(S <= W);
    std::uint64_t s = mask_;
    mask_ >>= S;
    return {s};
  }
  TRIVIAL [[nodiscard]] constexpr auto intmask() const -> std::int64_t {
    return mask_;
  }

  TRIVIAL constexpr auto operator~() const -> Bit<W> { return {~mask_}; }
  [[nodiscard]] TRIVIAL constexpr auto split() const
    -> std::array<Bit<W / 2>, 2> {
    return {Bit<W / 2>{mask_}, Bit<W / 2>{mask_ >> W}};
  }

private:
  TRIVIAL friend inline constexpr auto operator&(Bit<W> a, Bit<W> b) -> Bit<W> {
    return {a.mask_ & b.mask_};
  }
  TRIVIAL friend inline constexpr auto operator&(None<W>, Bit<W> b) -> Bit<W> {
    return b;
  }
  TRIVIAL friend inline constexpr auto operator&(Bit<W> a, None<W>) -> Bit<W> {
    return a;
  }
  TRIVIAL friend inline constexpr auto operator|(Bit<W> a, Bit<W> b) -> Bit<W> {
    return {a.mask_ | b.mask_};
  }
  TRIVIAL friend inline constexpr auto operator|(None<W>, Bit<W>) -> Bit<W> {
    return None<W>{};
  }
  TRIVIAL friend inline constexpr auto operator|(Bit<W>, None<W>) -> Bit<W> {
    return None<W>{};
  }
};
template <std::ptrdiff_t W> struct ExplicitLengthBit : Bit<W> {
  std::ptrdiff_t explicit_on_end_;
  TRIVIAL constexpr ExplicitLengthBit(std::uint64_t mask, std::ptrdiff_t on_end)
    : Bit<W>{mask}, explicit_on_end_(on_end) {}
  /// Values >= W indicate full masks
  TRIVIAL [[nodiscard]] constexpr auto onEnd() const -> std::ptrdiff_t {
    return explicit_on_end_;
  }
};
#endif // AVX512F
#ifdef __AVX512VL__
// In: iteration count `i.i` is the total length of the loop
// Out: mask for the final iteration. Zero indicates no masked iter.
template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i) -> ExplicitLengthBit<W> {
  static_assert(std::popcount(std::size_t(W)) == 1);
  utils::invariant(i >= 0);
  std::ptrdiff_t rem = i & (W - 1);
  return {__builtin_ia32_bzhi_di(0xffffffffffffffff, std::uint64_t(rem)), rem};
};
// In: index::Vector where `i.i` is for the current iteration, and total loop
// length. Out: mask for the current iteration, 0 indicates exit loop.
template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i, std::ptrdiff_t len)
  -> ExplicitLengthBit<W> {
  static_assert(std::popcount(std::size_t(W)) == 1);
  std::uint64_t x;
  if (__builtin_usubl_overflow(len, i, &x)) return {0, 0};
  if (x >= 64) return {0xffffffffffffffff, W};
  std::ptrdiff_t on_end = std::min(std::ptrdiff_t(x), W);
  return {__builtin_ia32_bzhi_di(0xffffffffffffffff, x), on_end};
};
// Requires: 0 <= m <= 255
template <std::ptrdiff_t W>
TRIVIAL constexpr auto createSmallPositive(std::ptrdiff_t m)
  -> ExplicitLengthBit<W> {
  static_assert(std::popcount(std::size_t(W)) == 1);
  utils::invariant(0 <= m);
  utils::invariant(m <= 255);
  std::ptrdiff_t on_end = std::min(m, W);
  return {__builtin_ia32_bzhi_di(0xffffffffffffffff, std::uint64_t(m)), on_end};
};

template <std::ptrdiff_t W> using Mask = Bit<W>;

#else // ifdef __AVX512VL__

template <std::ptrdiff_t W, std::size_t Bytes> struct Vector {
  static_assert(Bytes <= 8, "Only at most 8 bytes per element supported.");
  using I = utils::signed_integer_t<Bytes>;
  using V = Vec<W, I>;
  static_assert(sizeof(I) == Bytes);
  // static_assert(sizeof(I) * W <= VECTORWIDTH);
  // TODO: add support for smaller mask types, we we can use smaller eltypes
  V m;
  template <std::size_t newBytes>
  TRIVIAL constexpr operator Vector<W, newBytes>() const {
    if constexpr (newBytes != Bytes) {
      using S = utils::signed_integer_t<newBytes>;
      return {__builtin_convertvector(m, Vec<W, S>)};
    } else return *this;
  }
  TRIVIAL [[nodiscard]] constexpr auto intmask() const -> std::uint32_t {
    if constexpr (sizeof(I) == 8)
      if constexpr (W == 2) {
        __m128d arg = __builtin_bit_cast(__m128d, m);
        return _mm_movemask_pd(arg);
      } else return _mm256_movemask_pd(__builtin_bit_cast(__m256d, m));
    else if constexpr (sizeof(I) == 4)
      if constexpr (W == 4) {
        __m128 mm = __builtin_bit_cast(__m128, m);
        return _mm_movemask_ps(mm);
      } else return _mm256_movemask_ps(__builtin_bit_cast(__m256, m));
    else if constexpr (W == 16)
      return _mm_movemask_epi8(__builtin_bit_cast(__m128i, m));
    else return _mm256_movemask_epi8(__builtin_bit_cast(__m256i, m));
  }
  TRIVIAL [[nodiscard]] constexpr auto any() const -> bool { return intmask(); }
  TRIVIAL [[nodiscard]] constexpr auto popcount() const -> int {
    return std::popcount(intmask());
  }
  TRIVIAL [[nodiscard]] constexpr auto onBegin() const -> std::ptrdiff_t {
    return std::countr_zero(intmask());
  }
  TRIVIAL [[nodiscard]] constexpr auto onEnd() const -> std::ptrdiff_t {
    return 32 - std::countl_zero(intmask());
  }
  TRIVIAL [[nodiscard]] constexpr auto offBegin() const -> std::ptrdiff_t {
    return std::countr_one(intmask());
  }
  TRIVIAL [[nodiscard]] constexpr auto offEnd() const -> std::ptrdiff_t {
    std::uint32_t bitmask = (~intmask()) & ((1U << W) - 1U);
    return 32 - std::countl_zero(bitmask);
  }
  TRIVIAL constexpr operator __m128i() requires(sizeof(I) * W == 16) {
    return __builtin_bit_cast(__m128i, m);
  }
  TRIVIAL constexpr operator __m128d() requires(sizeof(I) * W == 16) {
    return __builtin_bit_cast(__m128d, m);
  }
  TRIVIAL constexpr operator __m128() requires(sizeof(I) * W == 16) {
    return __builtin_bit_cast(__m128, m);
  }
  TRIVIAL constexpr operator __m256i() requires(sizeof(I) * W == 32) {
    return __builtin_bit_cast(__m256i, m);
  }
  TRIVIAL constexpr operator __m256d() requires(sizeof(I) * W == 32) {
    return __builtin_bit_cast(__m256d, m);
  }
  TRIVIAL constexpr operator __m256() requires(sizeof(I) * W == 32) {
    return __builtin_bit_cast(__m256, m);
  }
  template <std::size_t NewBytes>
  TRIVIAL constexpr auto operator Vector<W, NewBytes>() const
    requires(NewBytes != Bytes) {
    using J = utils::signed_integer_t<NewBytes>;
    return {__builtin_convertvector(m, Vec<W, J>)};
  }
  TRIVIAL constexpr auto operator~() const -> Vector { return {~m}; }
  [[nodiscard]] TRIVIAL constexpr auto split() const
    -> std::array<Vector<W / 2, Bytes>, 2> {
    auto s = ::simd::split(m);
    return {s[0], s[1]};
  }

private:
  TRIVIAL friend constexpr auto operator&(Vector a, Vector b) -> Vector {
    return {a.m & b.m};
  }
  TRIVIAL friend constexpr auto operator&(mask::None<W>, Vector b) -> Vector {
    return b;
  }
  TRIVIAL friend constexpr auto operator&(Vector a, mask::None<W>) -> Vector {
    return a;
  }
  TRIVIAL friend constexpr auto operator|(Vector a, Vector b) -> Vector {
    return {a.m | b.m};
  }
  TRIVIAL friend constexpr auto operator|(mask::None<W>, Vector) -> None<W> {
    return {};
  }
  TRIVIAL friend constexpr auto operator|(Vector, mask::None<W>) -> None<W> {
    return {};
  }
};
static_assert(!std::convertible_to<Vector<2, 8>, Vector<4, 8>>);
static_assert(!std::convertible_to<Vector<4, 4>, Vector<8, 4>>);
template <std::ptrdiff_t W, std::size_t Bytes>
struct ExplicitLengthVector : Vector<W, Bytes> {
  std::ptrdiff_t explicit_on_end_;
  TRIVIAL constexpr ExplicitLengthVector(typename Vector<W, Bytes>::V mask_vec,
                                         std::ptrdiff_t on_end)
    : Vector<W, Bytes>{{mask_vec}}, explicit_on_end_(on_end) {}
  /// Values >= W indicate full masks
  TRIVIAL constexpr auto onEnd() const -> std::ptrdiff_t {
    return explicit_on_end_;
  }

  template <std::size_t newBytes>
  TRIVIAL constexpr operator ExplicitLengthVector<W, newBytes>() {
    if constexpr (newBytes != Bytes) {
      using S = utils::signed_integer_t<newBytes>;
      return {__builtin_convertvector(this->m, Vec<W, S>)};
    } else return *this;
  }
};
#ifdef __AVX512F__

// but no VL!!! xeon phi
template <std::ptrdiff_t W> TRIVIAL constexpr auto create(std::ptrdiff_t i) {
  if constexpr (W == 8) {
    std::ptrdiff_t rem = i & 7;
    return ExplicitLengthBit<8>{
      __builtin_ia32_bzhi_di(0xffffffffffffffff, std::uint64_t(rem)), rem};
  } else {
    std::ptrdiff_t rem = i & (W - 1);
    return ExplicitLengthVector<W, 8>{range<W, std::int64_t>() < rem, rem};
  }
}
template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i, std::ptrdiff_t len) {
  if constexpr (W == 8) {
    std::ptrdiff_t rem = len - i;
    return ExplicitLengthBit<8>{
      __builtin_ia32_bzhi_di(0xffffffffffffffff, std::uint64_t(rem)), rem};
  } else {
    std::ptrdiff_t rem = len - i;
    return ExplicitLengthVector<W, 8>{range<W, std::int64_t>() < rem, rem};
  }
}
template <std::ptrdiff_t W, typename I = std::int64_t>
using Mask = std::conditional_t<sizeof(I) * W == 64, Bit<W>, Vector<W, I>>;
#else  // ifdef __AVX512F__

template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i)
  -> ExplicitLengthVector<W, std::min(8z, VECTORWIDTH / W)> {
  static constexpr std::ptrdiff_t R = VECTORWIDTH / W;
  using I = utils::signed_integer_t<R >= 8 ? 8 : R>;
  std::ptrdiff_t rem = i & (W - 1);
  return {range<W, I>() < static_cast<I>(rem), rem};
}
template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i, std::ptrdiff_t len)
  -> ExplicitLengthVector<W, std::min(8z, VECTORWIDTH / W)> {
  static constexpr std::ptrdiff_t R = VECTORWIDTH / W;
  using I = utils::signed_integer_t<R >= 8 ? 8 : R>;
  std::ptrdiff_t rem = len - i;
  return {range<W, I>() < static_cast<I>(rem), rem};
}
template <std::ptrdiff_t W, typename I = std::int64_t>
using Mask = Vector<W, sizeof(I)>;
#endif // ifdef __AVX512F__; else

#endif // ifdef __AVX512VL__; else
#else  // ifdef __x86_64__

template <std::ptrdiff_t W, std::size_t Bytes> struct Vector {
  using I = utils::signed_integer_t<Bytes>;
  static_assert(sizeof(I) == Bytes);
  using V = Vec<W, I>;
  V m;
  template <std::size_t newBytes>
  TRIVIAL constexpr operator Vector<W, newBytes>() const {
    if constexpr (newBytes != Bytes) {
      using S = utils::signed_integer_t<newBytes>;
      return {__builtin_convertvector(m, Vec<W, S>)};
    } else return *this;
  }
  TRIVIAL [[nodiscard]] constexpr auto any() const -> bool {
    bool any{false};
    for (std::ptrdiff_t w = 0; w < W; ++w) any |= m[w];
    return any;
  }
  TRIVIAL [[nodiscard]] constexpr auto onBegin() const -> std::ptrdiff_t {
    for (std::ptrdiff_t w = 0; w < W; ++w)
      if (m[w]) return w;
    return W;
  }
  TRIVIAL [[nodiscard]] constexpr auto onEnd() const -> std::ptrdiff_t {
    std::ptrdiff_t l = 0;
    for (std::ptrdiff_t w = 0; w < W;)
      if (m[w++]) l = w;
    return l;
  }
  TRIVIAL [[nodiscard]] constexpr auto offBegin() const -> std::ptrdiff_t {
    for (std::ptrdiff_t w = 0; w < W; ++w)
      if (!m[w]) return w;
    return W;
  }
  TRIVIAL [[nodiscard]] constexpr auto offEnd() const -> std::ptrdiff_t {
    std::ptrdiff_t l = 0;
    for (std::ptrdiff_t w = 0; w < W; ++w)
      if (!m[w]) l = w;
    return l;
  }
  TRIVIAL [[nodiscard]] constexpr auto intmask() const -> std::uint32_t {
    std::uint32_t mask{};
    for (std::ptrdiff_t w = 0; w < W; ++w) mask |= stati_cast<bool>(m[w]) << w;
    return mask;
  }

private:
  TRIVIAL friend constexpr auto operator&(Vector a, Vector b) -> Vector {
    return {a.m & b.m};
  }
  TRIVIAL friend constexpr auto operator&(mask::None<W>, Vector b) -> Vector {
    return b;
  }
  TRIVIAL friend constexpr auto operator&(Vector a, mask::None<W>) -> Vector {
    return a;
  }
  TRIVIAL friend constexpr auto operator|(Vector a, Vector b) -> Vector {
    return {a.m | b.m};
  }
  TRIVIAL friend constexpr auto operator|(mask::None<W>, Vector) -> None<W> {
    return {};
  }
  TRIVIAL friend constexpr auto operator|(Vector, mask::None<W>) -> None<W> {
    return {};
  }
};

template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i) -> Vector<W, VECTORWIDTH / W> {
  // -> ExplicitLengthVector<W, VECTORWIDTH / W> {
  using I = utils::signed_integer_t<VECTORWIDTH / W>;
  std::ptrdiff_t rem = i & (W - 1);
  return {range<W, I>() < static_cast<I>(rem)};
  // return {range<W, I>() < static_cast<I>(rem), rem};
}
template <std::ptrdiff_t W>
TRIVIAL constexpr auto create(std::ptrdiff_t i, std::ptrdiff_t len)
  -> Vector<W, VECTORWIDTH / W> {
  // -> ExplicitLengthVector<W, VECTORWIDTH / W> {
  using I = utils::signed_integer_t<VECTORWIDTH / W>;
  std::ptrdiff_t rem = len - i;
  return {range<W, I>() < static_cast<I>(rem)};
  // return {range<W, I>() < static_cast<I>(rem), rem};
}
#endif // ifdef __x86_64__; else

} // namespace mask

namespace cmp {
#ifdef __AVX512VL__

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto eq(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 8)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 0)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 8)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 0)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 8)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 0)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 8)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 0)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 8)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 0)};
    else static_assert(false);
  } else if constexpr (W == 2) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128d, x),
                              __builtin_bit_cast(__m128d, y), 8)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 0)};
    else static_assert(false);
  } else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ne(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 4)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 4)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 4)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 4)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 4)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 4)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 4)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 4)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 4)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 4)};
    else static_assert(false);
  } else if constexpr (W == 2) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128d, x),
                              __builtin_bit_cast(__m128d, y), 4)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 4)};
    else static_assert(false);
  } else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto lt(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 25)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 1)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 25)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 1)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 25)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 1)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 25)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 1)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 25)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 1)};
    else static_assert(false);
  } else if constexpr (W == 2) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128d, y), 25)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 1)};
    else static_assert(false);
  } else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto gt(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 22)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 6)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 22)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 6)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 22)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 6)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 22)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 6)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 22)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 6)};
    else static_assert(false);
  } else if constexpr (W == 2) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128d, x),
                              __builtin_bit_cast(__m128d, y), 22)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 6)};
    else static_assert(false);
  } else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto le(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 26)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 2)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 26)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 2)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 26)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 2)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 26)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 2)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 26)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 2)};
    else static_assert(false);
  } else if constexpr (W == 2) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128d, x),
                              __builtin_bit_cast(__m128d, y), 26)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 2)};
    else static_assert(false);
  } else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ge(Vec<W, T> x, Vec<W, T> y)
  -> mask::Bit<W> requires(W == 16 || W == 8 || W == 4 || W == 2) {
  if constexpr (W == 16) {
    if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm512_cmp_ps_mask(__builtin_bit_cast(__m512, x),
                                 __builtin_bit_cast(__m512, y), 21)};
    else if constexpr (sizeof(T) == 4)
      return {_mm512_cmp_epi32_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 5)};
    else static_assert(false);
  } else if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 21)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 5)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm256_cmp_ps_mask(__builtin_bit_cast(__m256, x),
                                 __builtin_bit_cast(__m256, y), 21)};
    else if constexpr (sizeof(T) == 4)
      return {_mm256_cmp_epi32_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 5)};
    else static_assert(false);
  } else if constexpr (W == 4) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm256_cmp_pd_mask(__builtin_bit_cast(__m256d, x),
                                 __builtin_bit_cast(__m256d, y), 21)};
    else if constexpr (sizeof(T) == 8)
      return {_mm256_cmp_epi64_mask(__builtin_bit_cast(__m256i, x),
                                    __builtin_bit_cast(__m256i, y), 5)};
    else if constexpr (std::same_as<T, float>) // UQ (unordered quiet?)
      return {_mm_cmp_ps_mask(__builtin_bit_cast(__m128, x),
                              __builtin_bit_cast(__m128, y), 21)};
    else if constexpr (sizeof(T) == 4)
      return {_mm_cmp_epi32_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 5)};
    else static_assert(false);
  } else if constexpr (W == 2) {

    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm_cmp_pd_mask(__builtin_bit_cast(__m128d, x),
                              __builtin_bit_cast(__m128d, y), 21)};
    else if constexpr (sizeof(T) == 8)
      return {_mm_cmp_epi64_mask(__builtin_bit_cast(__m128i, x),
                                 __builtin_bit_cast(__m128i, y), 5)};
    else static_assert(false);
  } else static_assert(false);
}

#elifdef __AVX512F__

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto eq(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 8)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 0)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x == y};
  }
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ne(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 4)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 4)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x != y};
  }
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto lt(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 25)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 1)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x < y};
  }
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto gt(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 22)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 6)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x > y};
  }
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto le(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 26)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 2)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x <= y};
  }
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ge(Vec<W, T> x, Vec<W, T> y) {
  if constexpr (W == 8) {
    if constexpr (std::same_as<T, double>) // UQ (unordered quiet?)
      return {_mm512_cmp_pd_mask(__builtin_bit_cast(__m512d, x),
                                 __builtin_bit_cast(__m512d, y), 21)};
    else if constexpr (sizeof(T) == 8)
      return {_mm512_cmp_epi64_mask(__builtin_bit_cast(__m512i, x),
                                    __builtin_bit_cast(__m512i, y), 5)};
    else static_assert(false);
  } else {
    return mask::Vector<W>{x >= y};
  }
}

#else  // ifdef __AVX512VL__

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto eq(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x == y};
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ne(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x != y};
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto lt(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x < y};
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto gt(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x > y};
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto le(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x <= y};
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ge(Vec<W, T> x, Vec<W, T> y) -> mask::Vector<W, sizeof(T)>
  requires(W == 16 || W == 8 || W == 4 || W == 2) {
  return {x >= y};
}
#endif // ifdef __AVX512VL__; else

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto eq(T x, T y) -> bool requires(W == 1) {
  return x == y;
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ne(T x, T y) -> bool requires(W == 1) {
  return x != y;
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto lt(T x, T y) -> bool requires(W == 1) {
  return x < y;
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto gt(T x, T y) -> bool requires(W == 1) {
  return x > y;
}

template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto le(T x, T y) -> bool requires(W == 1) {
  return x <= y;
}
template <std::ptrdiff_t W, typename T>
TRIVIAL inline auto ge(T x, T y) -> bool requires(W == 1) {
  return x >= y;
}

} // namespace cmp
template <std::ptrdiff_t W,
          typename I = std::conditional_t<W == 2, std::int64_t, std::int32_t>>
TRIVIAL inline auto firstoff() {
  return cmp::ne<W, I>(range<W, I>(), Vec<W, I>{});
}

namespace mask {
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N,
          std::size_t Bytes>
struct Unroll {
  static constexpr std::ptrdiff_t W =
    std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
  static_assert(R * C > 0);
#ifdef __AVX512VL__
  using MaskType = mask::Bit<W>;
#elifdef __AVX512F__
  using MaskType =
    std::conditional_t<Bytes * W == 64, mask::Bit<W>, mask::Vector<W, Bytes>>;
#else
  using MaskType = mask::Vector<W, Bytes>;
#endif
  MaskType data_[R * C];

  TRIVIAL constexpr auto operator[](std::ptrdiff_t i) -> MaskType & {
    return data_[i];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t r, std::ptrdiff_t c)
    -> MaskType & {
    return data_[(r * C) + c];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t i) const -> MaskType {
    return data_[i];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t r, std::ptrdiff_t c) const
    -> MaskType {
    return data_[(r * C) + c];
  }

  TRIVIAL [[nodiscard]] constexpr auto any() const -> bool {
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      if (data_[i].any()) return true;
    return false;
  }
  TRIVIAL [[nodiscard]] constexpr auto popcount() const -> int {
    int count = data_[0].popcount();
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 1; i < R * C; ++i) count += data_[i].popcount();
    return false;
  }

  [[nodiscard]] TRIVIAL constexpr auto onBegin() const -> std::ptrdiff_t {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      if (auto begin = data_[i].onBegin(); begin < W) return (i * W) + begin;
    return R * C * W;
  }

  [[nodiscard]] TRIVIAL constexpr auto onEnd() const -> std::ptrdiff_t {
    std::ptrdiff_t last = 0;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      if (auto end = data_[i].onEnd(); end > 0) last = (i * W) + end;
    return last;
  }
  template <typename T>
  [[nodiscard]] TRIVIAL constexpr auto
  select(const ::simd::Unroll<R, C, N, T> &x,
         const ::simd::Unroll<R, C, N, T> &y) -> ::simd::Unroll<R, C, N, T>;

  template <typename T, std::ptrdiff_t CU, std::ptrdiff_t W>
  [[nodiscard]] TRIVIAL constexpr auto
  select(const ::simd::Unroll<R, CU, W, T> &x,
         const ::simd::Unroll<R, CU, W, T> &y)
    -> ::simd::Unroll<R, CU, W, T> requires((CU * W == C * N) && (CU != C));
  [[nodiscard]] TRIVIAL constexpr auto split() const requires(R == 1 || C == 1)
  {
    static_assert(R > 1 || C > 1);
    static constexpr std::ptrdiff_t Chalf = C >> 1;
    static constexpr std::ptrdiff_t Rhalf = R >> 1;
    static constexpr std::ptrdiff_t L = (R * C) >> 1;
    using U = std::conditional_t<R == 1, Unroll<1Z, Chalf, N, Bytes>,
                                 Unroll<Rhalf, 1Z, N, Bytes>>;

    if constexpr (L > 1) {
      std::array<U, 2> ret{};
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t i = 0; i < L; ++i) {
        ret[0].data_[i] = data_[i];
        ret[1].data_[i] = data_[i + L];
      }
      return ret;
    } else return std::array<U, 2>{U{data_[0]}, U{data_[1]}};
  }

  TRIVIAL constexpr auto operator~() const -> Unroll {
    Unroll result;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) result.data_[i] = ~data_[i];
    return result;
  }

private:
  TRIVIAL friend constexpr auto operator&(Unroll a, Unroll b) -> Unroll {
    Unroll result;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      result.data_[i] = a.data_[i] & b.data_[i];
    return result;
  }

  TRIVIAL friend constexpr auto operator|(Unroll a, Unroll b) -> Unroll {
    Unroll result;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      result.data_[i] = a.data_[i] | b.data_[i];
    return result;
  }
  TRIVIAL friend constexpr auto operator^(Unroll a, Unroll b) -> Unroll {
    Unroll result;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      result.data_[i] = a.data_[i] ^ b.data_[i];
    return result;
  }
};

// Specialization for 1x1 Unroll
template <std::ptrdiff_t N, std::size_t Bytes> struct Unroll<1Z, 1Z, N, Bytes> {
  static constexpr std::ptrdiff_t W =
    std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
#ifdef __AVX512VL__
  using MaskType = std::conditional_t<W == 1, bool, mask::Bit<W>>;
#elifdef __AVX512F__
  using MaskType = std::conditional_t<
    W == 1, bool,
    std::conditional_t<Bytes * W == 64, mask::Bit<W>, mask::Vector<W, Bytes>>>;
#else
  using MaskType = std::conditional_t<W == 1, bool, mask::Vector<W, Bytes>>;
#endif
  MaskType mask_;

  TRIVIAL constexpr auto operator[](std::ptrdiff_t) -> MaskType & {
    return mask_;
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t, std::ptrdiff_t)
    -> MaskType & {
    return mask_;
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t) const -> MaskType {
    return mask_;
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t, std::ptrdiff_t) const
    -> MaskType {
    return mask_;
  }

  TRIVIAL constexpr operator MaskType() const { return mask_; }
  TRIVIAL [[nodiscard]] constexpr auto any() const -> bool {
    if constexpr (W > 1) return mask_.any();
    else return mask_;
  }
  TRIVIAL [[nodiscard]] constexpr auto popcount() const -> int {
    return mask_.popcount();
  }

  [[nodiscard]] TRIVIAL constexpr auto onBegin() const -> std::ptrdiff_t {
    if constexpr (W > 1) return mask_.onBegin();
    else return !mask_;
  }

  [[nodiscard]] TRIVIAL constexpr auto onEnd() const -> std::ptrdiff_t {
    if constexpr (W > 1) return mask_.onEnd();
    else return mask_;
  }
  template <typename T>
  [[nodiscard]] TRIVIAL constexpr auto
  select(const ::simd::Unroll<1Z, 1Z, N, T> &x,
         const ::simd::Unroll<1Z, 1Z, N, T> &y) -> ::simd::Unroll<1Z, 1Z, N, T>;

  template <typename T, std::ptrdiff_t C, std::ptrdiff_t W>
  [[nodiscard]] TRIVIAL constexpr auto
  select(const ::simd::Unroll<1Z, C, W, T> &x,
         const ::simd::Unroll<1Z, C, W, T> &y)
    -> ::simd::Unroll<1Z, C, W, T> requires((C * W == N) && (C != 1Z));

  [[nodiscard]] TRIVIAL constexpr auto split() const {
    using U = Unroll<1Z, 1Z, N / 2, Bytes>;
    auto s = mask_.split();
    return std::array<U, 2>{U{s[0]}, U{s[1]}};
  }

  TRIVIAL constexpr operator bool() const requires(W == 1) { return mask_; }

  TRIVIAL constexpr auto operator~() const -> Unroll { return {~mask_}; }

private:
  TRIVIAL friend constexpr auto operator&(Unroll a, Unroll b) -> Unroll {
    return {a.mask_ & b.mask_};
  }

  TRIVIAL friend constexpr auto operator|(Unroll a, Unroll b) -> Unroll {
    return {a.mask_ | b.mask_};
  }
  TRIVIAL friend constexpr auto operator^(Unroll a, Unroll b) -> Unroll {
    return {a.mask_ ^ b.mask_};
  }
};
} // namespace mask

// Supported means by this library currently; more types may be added in the
// future as needed.

#ifndef POLYMATHNOEXPLICITSIMDARRAY
template <typename T>
concept SIMDSupported =
  (std::integral<T> || std::floating_point<T>) && (sizeof(T) >= 4);
#else
template <typename T>
concept SIMDSupported = false;
#endif

template <std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto vbroadcast(Vec<W, T> v) -> El<W, T> {
  if constexpr (W == 1) return v;
  else if constexpr (W == 2) return __builtin_shufflevector(v, v, 0, 0);
  else if constexpr (W == 4) return __builtin_shufflevector(v, v, 0, 0, 0, 0);
  else if constexpr (W == 8)
    return __builtin_shufflevector(v, v, 0, 0, 0, 0, 0, 0, 0, 0);
  else if constexpr (W == 16)
    return __builtin_shufflevector(v, v, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                   0, 0, 0);
  else if constexpr (W == 32)
    return __builtin_shufflevector(v, v, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                   0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                   0, 0, 0, 0);
  else if constexpr (W == 64)
    return __builtin_shufflevector(
      v, v, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
  else static_assert(false);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto vbroadcast(T x) -> El<W, T> {
  if constexpr (W > 1) {
    if consteval {
      return Vec<W, T>{} + x;
    } else {
      return vbroadcast<W, T>(Vec<W, T>{x});
    }
  } else return x;
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<1>) -> utils::value_t<T> {
  return *p;
}
template <typename T>
TRIVIAL constexpr auto load(const T *p, mask::None<1>, std::int32_t)
  -> utils::value_t<T> {
  return *p;
}
template <typename T> TRIVIAL inline void store(T *p, mask::None<1>, T x) {
  *p = x;
}
template <typename T>
TRIVIAL inline void store(T *p, mask::None<1>, T x, std::int32_t) {
  *p = x;
}
#ifdef __x86_64__

template <std::ptrdiff_t W, typename T> TRIVIAL consteval auto mmzero() {
  // Extend if/when supporting more types
  static_assert(std::popcount(std::size_t(W)) == 1 && (W * sizeof(T) <= 64));
  if constexpr (std::same_as<T, double>) {
    if constexpr (W == 8) return __m512d{};
    else if constexpr (W == 4) return __m256d{};
    else return __m128d{};
  } else if constexpr (std::same_as<T, float>) {
    if constexpr (W == 16) return __m512{};
    else if constexpr (W == 8) return __m256{};
    else return __m128{};
  } else {
    static_assert(std::integral<T>);
    if constexpr (W * sizeof(T) == 64) return __m512i{};
    else if constexpr (W * sizeof(T) == 32) return __m256i{};
    else return __m128i{};
  }
}

#ifdef __AVX512F__

template auto vbroadcast<8, std::int64_t>(Vec<8, std::int64_t>)
  -> Vec<8, std::int64_t>;

TRIVIAL inline auto load(const float *p, mask::None<16>) -> Vec<16, float> {
  return __builtin_bit_cast(Vec<16, float>, _mm512_loadu_ps(p));
}
TRIVIAL inline auto load(const std::int32_t *p, mask::None<16>)
  -> Vec<16, std::int32_t> {
  return __builtin_bit_cast(Vec<16, std::int32_t>, _mm512_loadu_ps(p));
}
TRIVIAL inline auto load(const std::uint32_t *p, mask::None<16>)
  -> Vec<16, std::uint32_t> {
  return __builtin_bit_cast(Vec<16, std::uint32_t>, _mm512_loadu_ps(p));
}
#ifdef __AVX512VL__
TRIVIAL inline auto load(const std::int16_t *p, mask::None<16>)
  -> Vec<16, std::int16_t> {
  return __builtin_bit_cast(Vec<16, std::int16_t>, _mm256_loadu_epi16(p));
}
#endif
TRIVIAL inline auto load(const std::int64_t *p, mask::Bit<8> i)
  -> Vec<8, std::int64_t> {
  return __builtin_bit_cast(Vec<8, std::int64_t>,
                            _mm512_maskz_loadu_epi64(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::uint64_t *p, mask::Bit<8> i)
  -> Vec<8, std::uint64_t> {
  return __builtin_bit_cast(Vec<8, std::uint64_t>,
                            _mm512_maskz_loadu_epi64(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const double *p, mask::Bit<8> i) -> Vec<8, double> {
  return __builtin_bit_cast(Vec<8, double>,
                            _mm512_maskz_loadu_pd(std::uint8_t(i.mask_), p));
}
#ifdef __AVX512VL__
TRIVIAL inline auto load(const float *p, mask::Bit<8> i) -> Vec<8, float> {
  return __builtin_bit_cast(Vec<8, float>,
                            _mm256_maskz_loadu_ps(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::int32_t *p, mask::Bit<8> i)
  -> Vec<8, std::int32_t> {
  return __builtin_bit_cast(Vec<8, std::int32_t>,
                            _mm256_maskz_loadu_epi32(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::uint32_t *p, mask::Bit<8> i)
  -> Vec<8, std::uint32_t> {
  return __builtin_bit_cast(Vec<8, std::uint32_t>,
                            _mm256_maskz_loadu_epi32(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::int16_t *p, mask::Bit<8> i)
  -> Vec<8, std::int16_t> {
  return __builtin_bit_cast(Vec<8, std::int16_t>,
                            _mm_maskz_loadu_epi16(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::uint16_t *p, mask::Bit<8> i)
  -> Vec<8, std::uint16_t> {
  return __builtin_bit_cast(Vec<8, std::uint16_t>,
                            _mm_maskz_loadu_epi16(std::uint8_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::int16_t *p, mask::Bit<16> i)
  -> Vec<16, std::int16_t> {
  return __builtin_bit_cast(
    Vec<16, std::int16_t>, _mm256_maskz_loadu_epi16(std::uint16_t(i.mask_), p));
}
#endif
TRIVIAL inline auto load(const float *p, mask::Bit<16> i) -> Vec<16, float> {
  return __builtin_bit_cast(Vec<16, float>,
                            _mm512_maskz_loadu_ps(std::uint16_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::int32_t *p, mask::Bit<16> i)
  -> Vec<16, std::int32_t> {
  return __builtin_bit_cast(
    Vec<16, std::int32_t>, _mm512_maskz_loadu_epi32(std::uint16_t(i.mask_), p));
}
TRIVIAL inline auto load(const std::uint32_t *p, mask::Bit<16> i)
  -> Vec<16, std::uint32_t> {
  return __builtin_bit_cast(
    Vec<16, std::uint32_t>,
    _mm512_maskz_loadu_epi32(std::uint16_t(i.mask_), p));
}
TRIVIAL inline void store(float *pt, mask::None<16>, Vec<16, float> x) {
  void *p = pt;
  __m512 xf = __builtin_bit_cast(__m512, x);
  _mm512_storeu_ps(p, xf);
}

TRIVIAL inline void store(std::int32_t *pt, mask::None<16>,
                          Vec<16, std::int32_t> x) {
  void *p = pt;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_storeu_epi32(p, xi);
}

TRIVIAL inline void store(std::uint32_t *pt, mask::None<16>,
                          Vec<16, std::uint32_t> x) {
  void *p = pt;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_storeu_epi32(p, xi);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(std::int16_t *pt, mask::None<16>,
                          Vec<16, std::int16_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_epi16(p, xi);
}

TRIVIAL inline void store(std::uint16_t *pt, mask::None<16>,
                          Vec<16, std::uint16_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_epi16(p, xi);
}
#endif
TRIVIAL inline void store(double *p, mask::Bit<8> i, Vec<8, double> x) {
  void *vp = p;
  __m512d xd = __builtin_bit_cast(__m512d, x);
  _mm512_mask_storeu_pd(vp, std::uint8_t(i.mask_), xd);
}

TRIVIAL inline void store(std::int64_t *p, mask::Bit<8> i,
                          Vec<8, std::int64_t> x) {
  void *vp = p;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_mask_storeu_epi64(vp, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::Bit<8> i,
                          Vec<8, std::uint64_t> x) {
  void *vp = p;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_mask_storeu_epi64(vp, std::uint8_t(i.mask_), xi);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(float *p, mask::Bit<8> i, Vec<8, float> x) {
  void *vp = p;
  __m256 xf = __builtin_bit_cast(__m256, x);
  _mm256_mask_storeu_ps(vp, std::uint8_t(i.mask_), xf);
}

TRIVIAL inline void store(std::int32_t *p, mask::Bit<8> i,
                          Vec<8, std::int32_t> x) {
  void *vp = p;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi32(vp, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::Bit<8> i,
                          Vec<8, std::uint32_t> x) {
  void *vp = p;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi32(vp, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::int16_t *p, mask::Bit<8> i,
                          Vec<8, std::int16_t> x) {
  void *vp = p;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_mask_storeu_epi16(vp, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint16_t *p, mask::Bit<8> i,
                          Vec<8, std::uint16_t> x) {
  void *vp = p;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_mask_storeu_epi16(vp, std::uint8_t(i.mask_), xi);
}
#endif
TRIVIAL inline void store(float *pt, mask::Bit<16> i, Vec<16, float> x) {
  void *p = pt;
  __m512 xf = __builtin_bit_cast(__m512, x);
  _mm512_mask_storeu_ps(p, std::uint16_t(i.mask_), xf);
}

TRIVIAL inline void store(std::int32_t *pt, mask::Bit<16> i,
                          Vec<16, std::int32_t> x) {
  void *p = pt;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_mask_storeu_epi32(p, std::uint16_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint32_t *pt, mask::Bit<16> i,
                          Vec<16, std::uint32_t> x) {
  void *p = pt;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_mask_storeu_epi32(p, std::uint16_t(i.mask_), xi);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(std::int16_t *pt, mask::Bit<16> i,
                          Vec<16, std::int16_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi16(p, std::uint16_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint16_t *pt, mask::Bit<16> i,
                          Vec<16, std::uint16_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi16(p, std::uint16_t(i.mask_), xi);
}
#endif

// strided memory accesses
TRIVIAL inline auto gather(const float *pt, mask::None<16>,
                           Vec<16, std::int32_t> i) -> Vec<16, float> {
  auto inds = __builtin_bit_cast(__m512i, i);
  const void *p = pt;
  return __builtin_bit_cast(Vec<16, float>, _mm512_i32gather_ps(inds, p, 4));
}
TRIVIAL inline auto gather(const std::int32_t *pt, mask::None<16>,
                           Vec<16, std::int32_t> i) -> Vec<16, std::int32_t> {
  auto inds = __builtin_bit_cast(__m512i, i);
  const void *p = pt;
  return __builtin_bit_cast(Vec<16, std::int32_t>,
                            _mm512_i32gather_ps(inds, p, 4));
}
template <typename std::uint32_t>
TRIVIAL inline auto gather(const std::uint32_t *pt, mask::None<16>,
                           Vec<16, std::int32_t> i) -> Vec<16, std::uint32_t> {
  auto inds = __builtin_bit_cast(__m512i, i);
  const void *p = pt;
  return __builtin_bit_cast(Vec<16, std::uint32_t>,
                            _mm512_i32gather_epi32(inds, p, 4));
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<16>, std::int32_t stride)
  -> Vec<16, T> {
  return gather(p, mask::None<16>{}, range<16>() * stride);
}
TRIVIAL inline auto gather(const double *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, double> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, double>();
  return __builtin_bit_cast(
    Vec<8, double>,
    _mm512_mask_i32gather_pd(src, std::uint8_t(i.mask_), inds, p, 8));
}

TRIVIAL inline auto gather(const std::int64_t *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::int64_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::int64_t>();
  return __builtin_bit_cast(
    Vec<8, std::int64_t>,
    _mm512_mask_i32gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
}

TRIVIAL inline auto gather(const std::uint64_t *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::uint64_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::uint64_t>();
  return __builtin_bit_cast(
    Vec<8, std::uint64_t>,
    _mm512_mask_i32gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
}

#ifdef __AVX512VL__
TRIVIAL inline auto gather(const float *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, float> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, float>();
  return __builtin_bit_cast(
    Vec<8, float>,
    _mm256_mmask_i32gather_ps(src, std::uint8_t(i.mask_), inds, p, 4));
}

TRIVIAL inline auto gather(const std::int32_t *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::int32_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::int32_t>();
  return __builtin_bit_cast(
    Vec<8, std::int32_t>,
    _mm256_mmask_i32gather_epi32(src, std::uint8_t(i.mask_), inds, p, 4));
}

TRIVIAL inline auto gather(const std::uint32_t *pt, mask::Bit<8> i,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::uint32_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::uint32_t>();
  return __builtin_bit_cast(
    Vec<8, std::uint32_t>,
    _mm256_mmask_i32gather_epi32(src, std::uint8_t(i.mask_), inds, p, 4));
}
#endif
TRIVIAL inline auto gather(const double *pt, mask::Bit<8> i,
                           Vec<8, std::int64_t> indv) -> Vec<8, double> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, double>();
  return __builtin_bit_cast(
    Vec<8, double>,
    _mm512_mask_i64gather_pd(src, std::uint8_t(i.mask_), inds, p, 8));
}

TRIVIAL inline auto gather(const std::int64_t *pt, mask::Bit<8> i,
                           Vec<8, std::int64_t> indv) -> Vec<8, std::int64_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::int64_t>();
  return __builtin_bit_cast(
    Vec<8, std::int64_t>,
    _mm512_mask_i64gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
}

TRIVIAL inline auto gather(const std::uint64_t *pt, mask::Bit<8> i,
                           Vec<8, std::int64_t> indv) -> Vec<8, std::uint64_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  static constexpr auto src = mmzero<8, std::uint64_t>();
  return __builtin_bit_cast(
    Vec<8, std::uint64_t>,
    _mm512_mask_i64gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Bit<8> i, std::int32_t stride)
  -> Vec<8, T> {
  return gather(p, i, range<8>() * stride);
}
TRIVIAL inline auto gather(const float *pt, mask::Bit<16> i,
                           Vec<16, std::int32_t> indv) -> Vec<16, float> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  auto src = mmzero<16, float>();
  return __builtin_bit_cast(
    Vec<16, float>,
    _mm512_mask_i32gather_ps(src, std::uint16_t(i.mask_), inds, p, 4));
}

TRIVIAL inline auto gather(const std::int32_t *pt, mask::Bit<16> i,
                           Vec<16, std::int32_t> indv)
  -> Vec<16, std::int32_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  auto src = mmzero<16, std::int32_t>();
  return __builtin_bit_cast(
    Vec<16, std::int32_t>,
    _mm512_mask_i32gather_epi32(src, std::uint16_t(i.mask_), inds, p, 4));
}

TRIVIAL inline auto gather(const std::uint32_t *pt, mask::Bit<16> i,
                           Vec<16, std::int32_t> indv)
  -> Vec<16, std::uint32_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const void *p = pt;
  auto src = mmzero<16, std::uint32_t>();
  return __builtin_bit_cast(
    Vec<16, std::uint32_t>,
    _mm512_mask_i32gather_epi32(src, std::uint16_t(i.mask_), inds, p, 4));
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Bit<16> i, std::int32_t stride)
  -> Vec<16, T> {
  return gather(p, i, range<16>() * stride);
}
TRIVIAL inline void scatter(double *pt, mask::None<8>, Vec<8, double> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_i32scatter_pd(p, inds, __builtin_bit_cast(__m512d, x), 8);
}

TRIVIAL inline void scatter(std::int64_t *pt, mask::None<8>,
                            Vec<8, std::int64_t> x, Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_i32scatter_epi64(p, inds, __builtin_bit_cast(__m512i, x), 8);
}

TRIVIAL inline void scatter(std::uint64_t *pt, mask::None<8>,
                            Vec<8, std::uint64_t> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_i32scatter_epi64(p, inds, __builtin_bit_cast(__m512i, x), 8);
}

#ifdef __AVX512VL__
TRIVIAL inline void scatter(float *pt, mask::None<8>, Vec<8, float> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_i32scatter_ps(p, inds, __builtin_bit_cast(__m256, x), 4);
}

TRIVIAL inline void scatter(std::int32_t *pt, mask::None<8>,
                            Vec<8, std::int32_t> x, Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_i32scatter_epi32(p, inds, __builtin_bit_cast(__m256i, x), 4);
}

TRIVIAL inline void scatter(std::uint32_t *pt, mask::None<8>,
                            Vec<8, std::uint32_t> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_i32scatter_epi32(p, inds, __builtin_bit_cast(__m256i, x), 4);
}
#endif
template <typename T>
TRIVIAL inline void store(T *p, mask::None<8>, Vec<8, T> x,
                          std::int32_t stride) {
  scatter(p, mask::None<8>{}, x, range<8>() * stride);
}

TRIVIAL inline void scatter(float *pt, mask::None<16>, Vec<16, float> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_i32scatter_ps(p, inds, __builtin_bit_cast(__m512, x), 4);
}

TRIVIAL inline void scatter(std::int32_t *pt, mask::None<16>,
                            Vec<16, std::int32_t> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_i32scatter_epi32(p, inds, __builtin_bit_cast(__m512i, x), 4);
}

TRIVIAL inline void scatter(std::uint32_t *pt, mask::None<16>,
                            Vec<16, std::uint32_t> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_i32scatter_epi32(p, inds, __builtin_bit_cast(__m512i, x), 4);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::None<16>, Vec<16, T> x,
                          std::int32_t stride) {
  scatter(p, mask::None<16>{}, x, range<16>() * stride);
}
TRIVIAL inline void scatter(double *pt, mask::Bit<8> i, Vec<8, double> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_pd(p, std::uint8_t(i.mask_), inds,
                            __builtin_bit_cast(__m512d, x), 8);
}

TRIVIAL inline void scatter(std::int64_t *pt, mask::Bit<8> i,
                            Vec<8, std::int64_t> x, Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_epi64(p, std::uint8_t(i.mask_), inds,
                               __builtin_bit_cast(__m512i, x), 8);
}

TRIVIAL inline void scatter(std::uint64_t *pt, mask::Bit<8> i,
                            Vec<8, std::uint64_t> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_epi64(p, std::uint8_t(i.mask_), inds,
                               __builtin_bit_cast(__m512i, x), 8);
}

#ifdef __AVX512VL__
TRIVIAL inline void scatter(float *pt, mask::Bit<8> i, Vec<8, float> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_mask_i32scatter_ps(p, std::uint8_t(i.mask_), inds,
                            __builtin_bit_cast(__m256, x), 4);
}

TRIVIAL inline void scatter(std::int32_t *pt, mask::Bit<8> i,
                            Vec<8, std::int32_t> x, Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_mask_i32scatter_epi32(p, std::uint8_t(i.mask_), inds,
                               __builtin_bit_cast(__m256i, x), 4);
}

TRIVIAL inline void scatter(std::uint32_t *pt, mask::Bit<8> i,
                            Vec<8, std::uint32_t> x,
                            Vec<8, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m256i, indv);
  void *p = pt;
  _mm256_mask_i32scatter_epi32(p, std::uint8_t(i.mask_), inds,
                               __builtin_bit_cast(__m256i, x), 4);
}
#endif
template <typename T>
TRIVIAL inline void store(T *p, mask::Bit<8> i, Vec<8, T> x,
                          std::int32_t stride) {
  scatter(p, i, x, range<8>() * stride);
}
TRIVIAL inline void scatter(float *pt, mask::Bit<16> i, Vec<16, float> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_ps(p, std::uint16_t(i.mask_), inds,
                            __builtin_bit_cast(__m512, x), 4);
}

TRIVIAL inline void scatter(std::int32_t *pt, mask::Bit<16> i,
                            Vec<16, std::int32_t> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_epi32(p, std::uint16_t(i.mask_), inds,
                               __builtin_bit_cast(__m512i, x), 4);
}

TRIVIAL inline void scatter(std::uint32_t *pt, mask::Bit<16> i,
                            Vec<16, std::uint32_t> x,
                            Vec<16, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m512i, indv);
  void *p = pt;
  _mm512_mask_i32scatter_epi32(p, std::uint16_t(i.mask_), inds,
                               __builtin_bit_cast(__m512i, x), 4);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Bit<16> i, Vec<16, T> x,
                          std::int32_t stride) {
  scatter(p, i, x, range<16>() * stride);
}
TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, double> x,
                              Vec<8, double> y) -> Vec<8, double> {
  __m512d xd = __builtin_bit_cast(__m512d, x),
          yd = __builtin_bit_cast(__m512d, y);
  return __builtin_bit_cast(Vec<8, double>,
                            _mm512_mask_mov_pd(yd, std::uint8_t(m.mask_), xd));
}

TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, std::int64_t> x,
                              Vec<8, std::int64_t> y) -> Vec<8, std::int64_t> {
  __m512i xi = __builtin_bit_cast(__m512i, x),
          yi = __builtin_bit_cast(__m512i, y);
  return __builtin_bit_cast(
    Vec<8, std::int64_t>, _mm512_mask_mov_epi64(yi, std::uint8_t(m.mask_), xi));
}

TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, std::uint64_t> x,
                              Vec<8, std::uint64_t> y)
  -> Vec<8, std::uint64_t> {
  __m512i xi = __builtin_bit_cast(__m512i, x),
          yi = __builtin_bit_cast(__m512i, y);
  return __builtin_bit_cast(
    Vec<8, std::uint64_t>,
    _mm512_mask_mov_epi64(yi, std::uint8_t(m.mask_), xi));
}

#ifdef __AVX512VL__
TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, float> x, Vec<8, float> y)
  -> Vec<8, float> {
  __m256 xf = __builtin_bit_cast(__m256, x), yf = __builtin_bit_cast(__m256, y);
  return __builtin_bit_cast(Vec<8, float>,
                            _mm256_mask_mov_ps(yf, std::uint8_t(m.mask_), xf));
}

TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, std::int32_t> x,
                              Vec<8, std::int32_t> y) -> Vec<8, std::int32_t> {
  __m256i xi = __builtin_bit_cast(__m256i, x),
          yi = __builtin_bit_cast(__m256i, y);
  return __builtin_bit_cast(
    Vec<8, std::int32_t>, _mm256_mask_mov_epi32(yi, std::uint8_t(m.mask_), xi));
}

TRIVIAL constexpr auto select(mask::Bit<8> m, Vec<8, std::uint32_t> x,
                              Vec<8, std::uint32_t> y)
  -> Vec<8, std::uint32_t> {
  __m256i xi = __builtin_bit_cast(__m256i, x),
          yi = __builtin_bit_cast(__m256i, y);
  return __builtin_bit_cast(
    Vec<8, std::uint32_t>,
    _mm256_mask_mov_epi32(yi, std::uint8_t(m.mask_), xi));
}
#endif

TRIVIAL constexpr auto select(mask::Bit<16> m, Vec<16, float> x,
                              Vec<16, float> y) -> Vec<16, float> {
  __m512 xf = __builtin_bit_cast(__m512, x), yf = __builtin_bit_cast(__m512, y);
  return __builtin_bit_cast(Vec<16, float>,
                            _mm512_mask_mov_ps(yf, std::uint16_t(m.mask_), xf));
}

TRIVIAL constexpr auto select(mask::Bit<16> m, Vec<16, std::int32_t> x,
                              Vec<16, std::int32_t> y)
  -> Vec<16, std::int32_t> {
  __m512i xi = __builtin_bit_cast(__m512i, x),
          yi = __builtin_bit_cast(__m512i, y);
  return __builtin_bit_cast(
    Vec<16, std::int32_t>,
    _mm512_mask_mov_epi32(yi, std::uint16_t(m.mask_), xi));
}

TRIVIAL constexpr auto select(mask::Bit<16> m, Vec<16, std::uint32_t> x,
                              Vec<16, std::uint32_t> y)
  -> Vec<16, std::uint32_t> {
  __m512i xi = __builtin_bit_cast(__m512i, x),
          yi = __builtin_bit_cast(__m512i, y);
  return __builtin_bit_cast(
    Vec<16, std::uint32_t>,
    _mm512_mask_mov_epi32(yi, std::uint16_t(m.mask_), xi));
}

#endif // AVX512F
#ifdef __AVX__
TRIVIAL inline auto load(const float *p, mask::None<8>) -> Vec<8, float> {
  return __builtin_bit_cast(Vec<8, float>, _mm256_loadu_ps(p));
}

#ifdef __AVX512F__
TRIVIAL inline auto load(const std::int32_t *p, mask::None<8>)
  -> Vec<8, std::int32_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::int32_t>, _mm256_loadu_epi32(vp));
}

TRIVIAL inline auto load(const std::uint32_t *p, mask::None<8>)
  -> Vec<8, std::uint32_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::uint32_t>, _mm256_loadu_epi32(vp));
}

TRIVIAL inline auto load(const std::int16_t *p, mask::None<8>)
  -> Vec<8, std::int16_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::int16_t>, _mm_loadu_epi16(vp));
}

TRIVIAL inline auto load(const std::uint16_t *p, mask::None<8>)
  -> Vec<8, std::uint16_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::uint16_t>, _mm_loadu_epi16(vp));
}

TRIVIAL inline auto load(const double *p, mask::None<8>) -> Vec<8, double> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, double>, _mm512_loadu_pd(vp));
}

TRIVIAL inline auto load(const std::int64_t *p, mask::None<8>)
  -> Vec<8, std::int64_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::int64_t>, _mm512_loadu_epi64(vp));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::None<8>)
  -> Vec<8, std::uint64_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<8, std::uint64_t>, _mm512_loadu_epi64(vp));
}
#else
TRIVIAL inline auto load(const std::int32_t *p, mask::None<8>)
  -> Vec<8, std::int32_t> {
  const __m256i *pi = reinterpret_cast<const __m256i *>(p);
  return __builtin_bit_cast(Vec<8, std::int32_t>, _mm256_loadu_si256(pi));
}

TRIVIAL inline auto load(const std::uint32_t *p, mask::None<8>)
  -> Vec<8, std::uint32_t> {
  const __m256i *pi = reinterpret_cast<const __m256i *>(p);
  return __builtin_bit_cast(Vec<8, std::uint32_t>, _mm256_loadu_si256(pi));
}

TRIVIAL inline auto load(const std::int16_t *p, mask::None<8>)
  -> Vec<8, std::int16_t> {
  const __m128i *pi = reinterpret_cast<const __m128i *>(p);
  return __builtin_bit_cast(Vec<8, std::int16_t>, _mm_loadu_si128(pi));
}

TRIVIAL inline auto load(const std::uint16_t *p, mask::None<8>)
  -> Vec<8, std::uint16_t> {
  const __m128i *pi = reinterpret_cast<const __m128i *>(p);
  return __builtin_bit_cast(Vec<8, std::uint16_t>, _mm_loadu_si128(pi));
}
#endif
TRIVIAL inline void store(float *p, mask::None<8>, Vec<8, float> x) {
  __m256 xf = __builtin_bit_cast(__m256, x);
  _mm256_storeu_ps(p, xf);
}

#ifdef __AVX512F__
TRIVIAL inline void store(std::int32_t *p, mask::None<8>,
                          Vec<8, std::int32_t> x) {
  void *vp = p;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_epi32(vp, xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::None<8>,
                          Vec<8, std::uint32_t> x) {
  void *vp = p;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_epi32(vp, xi);
}

TRIVIAL inline void store(std::int16_t *p, mask::None<8>,
                          Vec<8, std::int16_t> x) {
  void *vp = p;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_epi16(vp, xi);
}

TRIVIAL inline void store(std::uint16_t *p, mask::None<8>,
                          Vec<8, std::uint16_t> x) {
  void *vp = p;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_epi16(vp, xi);
}

TRIVIAL inline void store(double *p, mask::None<8>, Vec<8, double> x) {
  void *vp = p;
  __m512d xd = __builtin_bit_cast(__m512d, x);
  _mm512_storeu_pd(vp, xd);
}

TRIVIAL inline void store(std::int64_t *p, mask::None<8>,
                          Vec<8, std::int64_t> x) {
  void *vp = p;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_storeu_epi64(vp, xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::None<8>,
                          Vec<8, std::uint64_t> x) {
  void *vp = p;
  __m512i xi = __builtin_bit_cast(__m512i, x);
  _mm512_storeu_epi64(vp, xi);
}
#else
TRIVIAL inline void store(std::int32_t *p, mask::None<8>,
                          Vec<8, std::int32_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_si256(reinterpret_cast<__m256i *>(p), xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::None<8>,
                          Vec<8, std::uint32_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_storeu_si256(reinterpret_cast<__m256i *>(p), xi);
}

TRIVIAL inline void store(std::int16_t *p, mask::None<8>,
                          Vec<8, std::int16_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_si128(reinterpret_cast<__m128i *>(p), xi);
}

TRIVIAL inline void store(std::uint16_t *p, mask::None<8>,
                          Vec<8, std::uint16_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_si128(reinterpret_cast<__m128i *>(p), xi);
}
#endif
#ifdef __AVX2__
// Non-masked gather is same with AVX512VL and AVX2
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<4>, Vec<4, std::int32_t> indv)
  -> Vec<4, T> {
  auto x = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(Vec<4, double>, _mm256_i32gather_pd(p, x, 8));
  else if constexpr (std::same_as<T, float>)
    return __builtin_bit_cast(Vec<4, float>, _mm_i32gather_ps(p, x, 4));
  else if constexpr (sizeof(T) == 8) {
    const long long int *pi = reinterpret_cast<const long long int *>(p);
    return __builtin_bit_cast(Vec<4, T>, _mm256_i32gather_epi64(pi, x, 8));
  } else if constexpr (sizeof(T) == 4)
    return __builtin_bit_cast(Vec<4, T>, _mm_i32gather_epi32(p, x, 4));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<4>, Vec<4, std::int64_t> indv)
  -> Vec<4, T> {
  auto x = __builtin_bit_cast(__m256i, indv);
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(Vec<4, double>, _mm256_i64gather_pd(p, x, 8));
  else if constexpr (sizeof(T) == 8) {
    const long long int *pi = reinterpret_cast<const long long int *>(p);
    return __builtin_bit_cast(Vec<4, T>, _mm256_i64gather_epi64(pi, x, 8));
  } else static_assert(false);
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<4>, std::int32_t stride)
  -> Vec<4, T> {
  return gather(p, mask::None<4>{}, range<4>() * stride);
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<2>, Vec<2, std::int64_t> indv)
  -> Vec<2, T> {
  auto x = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(Vec<2, double>, _mm_i64gather_pd(p, x, 8));
  else if constexpr (sizeof(T) == 8) {
    const long long int *pi = reinterpret_cast<const long long int *>(p);
    return __builtin_bit_cast(Vec<2, T>, _mm_i64gather_epi64(pi, x, 8));
  } else static_assert(false);
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<2>, std::int32_t stride)
  -> Vec<2, T> {
  return gather(p, mask::None<2>{}, range<2>() * stride);
}
TRIVIAL inline auto gather(const float *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, float> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  return __builtin_bit_cast(Vec<8, float>, _mm256_i32gather_ps(p, inds, 4));
}

TRIVIAL inline auto gather(const std::int32_t *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::int32_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  return __builtin_bit_cast(Vec<8, std::int32_t>,
                            _mm256_i32gather_epi32(p, inds, 4));
}

TRIVIAL inline auto gather(const std::uint32_t *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::uint32_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  return __builtin_bit_cast(Vec<8, std::uint32_t>,
                            _mm256_i32gather_epi32(p, inds, 4));
}

#ifdef __AVX512F__
TRIVIAL inline auto gather(const double *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, double> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  return __builtin_bit_cast(Vec<8, double>, _mm512_i32gather_pd(inds, p, 8));
}

TRIVIAL inline auto gather(const std::int64_t *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::int64_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const long long int *pi = reinterpret_cast<const long long int *>(p);
  return __builtin_bit_cast(Vec<8, std::int64_t>,
                            _mm512_i32gather_epi64(inds, pi, 8));
}

TRIVIAL inline auto gather(const std::uint64_t *p, mask::None<8>,
                           Vec<8, std::int32_t> indv) -> Vec<8, std::uint64_t> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  const long long int *pi = reinterpret_cast<const long long int *>(p);
  return __builtin_bit_cast(Vec<8, std::uint64_t>,
                            _mm512_i32gather_epi64(inds, pi, 8));
}
#endif
#ifdef __AVX512F__
TRIVIAL inline auto gather(const double *p, mask::None<8>,
                           Vec<8, std::int64_t> indv) -> Vec<8, double> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  return __builtin_bit_cast(Vec<8, double>, _mm512_i64gather_pd(inds, p, 8));
}

TRIVIAL inline auto gather(const std::int64_t *p, mask::None<8>,
                           Vec<8, std::int64_t> indv) -> Vec<8, std::int64_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const long long int *pi = reinterpret_cast<const long long int *>(p);
  return __builtin_bit_cast(Vec<8, std::int64_t>,
                            _mm512_i64gather_epi64(inds, pi, 8));
}

TRIVIAL inline auto gather(const std::uint64_t *p, mask::None<8>,
                           Vec<8, std::int64_t> indv) -> Vec<8, std::uint64_t> {
  auto inds = __builtin_bit_cast(__m512i, indv);
  const long long int *pi = reinterpret_cast<const long long int *>(p);
  return __builtin_bit_cast(Vec<8, std::uint64_t>,
                            _mm512_i64gather_epi64(inds, pi, 8));
}
#endif // AVX512F
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<8>, std::int32_t stride)
  -> Vec<8, T> {
  return gather(p, mask::None<8>{}, range<8>() * stride);
}
#endif // AVX2
#endif // AVX

// Here, we handle masked loads/stores
#ifdef __AVX512VL__
template <typename T>
TRIVIAL inline auto load(const T *pt, mask::Bit<4> i) -> Vec<4, T> {
  const void *p = pt;
  if constexpr (std::same_as<T, double>) {
    return __builtin_bit_cast(Vec<4, double>,
                              _mm256_maskz_loadu_pd(std::uint8_t(i.mask_), p));
  } else if constexpr (sizeof(T) == 8) {
    return __builtin_bit_cast(
      Vec<4, T>, _mm256_maskz_loadu_epi64(std::uint8_t(i.mask_), p));
  } else if constexpr (std::same_as<T, float>) {
    return __builtin_bit_cast(Vec<4, float>,
                              _mm_maskz_loadu_ps(std::uint8_t(i.mask_), p));
  } else if constexpr (sizeof(T) == 4) {
    return __builtin_bit_cast(Vec<4, T>,
                              _mm_maskz_loadu_epi32(std::uint8_t(i.mask_), p));
  } else static_assert(false);
}
TRIVIAL inline void store(double *pt, mask::Bit<4> i, Vec<4, double> x) {
  void *p = pt;
  __m256d xd = __builtin_bit_cast(__m256d, x);
  _mm256_mask_storeu_pd(p, std::uint8_t(i.mask_), xd);
}

TRIVIAL inline void store(std::int64_t *pt, mask::Bit<4> i,
                          Vec<4, std::int64_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi64(p, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint64_t *pt, mask::Bit<4> i,
                          Vec<4, std::uint64_t> x) {
  void *p = pt;
  __m256i xi = __builtin_bit_cast(__m256i, x);
  _mm256_mask_storeu_epi64(p, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(float *pt, mask::Bit<4> i, Vec<4, float> x) {
  void *p = pt;
  __m128 xf = __builtin_bit_cast(__m128, x);
  _mm_mask_storeu_ps(p, std::uint8_t(i.mask_), xf);
}

TRIVIAL inline void store(std::int32_t *pt, mask::Bit<4> i,
                          Vec<4, std::int32_t> x) {
  void *p = pt;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_mask_storeu_epi32(p, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline void store(std::uint32_t *pt, mask::Bit<4> i,
                          Vec<4, std::uint32_t> x) {
  void *p = pt;
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_mask_storeu_epi32(p, std::uint8_t(i.mask_), xi);
}

TRIVIAL inline auto load(const double *p, mask::Bit<2> i) -> Vec<2, double> {
  return __builtin_bit_cast(Vec<2, double>,
                            _mm_maskz_loadu_pd(std::uint8_t(i.mask_), p));
}

TRIVIAL inline auto load(const std::int64_t *p, mask::Bit<2> i)
  -> Vec<2, std::int64_t> {
  return __builtin_bit_cast(Vec<2, std::int64_t>,
                            _mm_maskz_loadu_epi64(std::uint8_t(i.mask_), p));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::Bit<2> i)
  -> Vec<2, std::uint64_t> {
  return __builtin_bit_cast(Vec<2, std::uint64_t>,
                            _mm_maskz_loadu_epi64(std::uint8_t(i.mask_), p));
}
TRIVIAL inline void store(double *p, mask::Bit<2> i, Vec<2, double> x) {
  _mm_mask_storeu_pd(p, std::uint8_t(i.mask_), __builtin_bit_cast(__m128d, x));
}

TRIVIAL inline void store(std::int64_t *p, mask::Bit<2> i,
                          Vec<2, std::int64_t> x) {
  _mm_mask_storeu_epi64(p, std::uint8_t(i.mask_),
                        __builtin_bit_cast(__m128i, x));
}

TRIVIAL inline void store(std::uint64_t *p, mask::Bit<2> i,
                          Vec<2, std::uint64_t> x) {
  _mm_mask_storeu_epi64(p, std::uint8_t(i.mask_),
                        __builtin_bit_cast(__m128i, x));
}
// gather/scatter
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Bit<4> i,
                           Vec<4, std::int32_t> indv) -> Vec<4, T> {
  auto inds = __builtin_bit_cast(__m128i, indv);
  auto src{mmzero<4, T>()};
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(
      Vec<4, double>,
      _mm256_mmask_i32gather_pd(src, std::uint8_t(i.mask_), inds, p, 8));
  else if constexpr (sizeof(T) == 8)
    return __builtin_bit_cast(
      Vec<4, T>,
      _mm256_mmask_i32gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
  else if constexpr (std::same_as<T, float>)
    return __builtin_bit_cast(
      Vec<4, float>,
      _mm_mmask_i32gather_ps(src, std::uint8_t(i.mask_), inds, p, 4));
  else if constexpr (sizeof(T) == 4)
    return __builtin_bit_cast(
      Vec<4, T>,
      _mm_mmask_i32gather_epi32(src, std::uint8_t(i.mask_), inds, p, 4));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Bit<4> i,
                           Vec<4, std::int64_t> indv) -> Vec<4, T> {
  auto inds = __builtin_bit_cast(__m256i, indv);
  auto src{mmzero<4, T>()};
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(
      Vec<4, double>,
      _mm256_mmask_i64gather_pd(src, std::uint8_t(i.mask_), inds, p, 8));
  else if constexpr (sizeof(T) == 8)
    return __builtin_bit_cast(
      Vec<4, T>,
      _mm256_mmask_i64gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Bit<4> i, std::int32_t stride)
  -> Vec<4, T> {
  return gather(p, i, range<4>() * stride);
}

template <typename T>
TRIVIAL inline void scatter(T *p, mask::None<4>, Vec<4, T> x,
                            Vec<4, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    _mm256_i32scatter_pd(p, inds, __builtin_bit_cast(__m256d, x), 8);
  else if constexpr (sizeof(T) == 8)
    _mm256_i32scatter_epi64(p, inds, __builtin_bit_cast(__m256i, x), 8);
  else if constexpr (std::same_as<T, float>)
    _mm_i32scatter_ps(p, inds, __builtin_bit_cast(__m128, x), 4);
  else if constexpr (sizeof(T) == 4)
    _mm_i32scatter_epi32(p, inds, __builtin_bit_cast(__m128i, x), 4);
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::None<4>, Vec<4, T> x,
                          std::int32_t stride) {
  scatter(p, mask::None<4>{}, x, range<4>() * stride);
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::Bit<4> i, Vec<4, T> x,
                            Vec<4, std::int32_t> indv) {
  auto inds = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    _mm256_mask_i32scatter_pd(p, std::uint8_t(i.mask_), inds,
                              __builtin_bit_cast(__m256d, x), 8);
  else if constexpr (sizeof(T) == 8)
    _mm256_mask_i32scatter_epi64(p, std::uint8_t(i.mask_), inds,
                                 __builtin_bit_cast(__m256i, x), 8);
  else if constexpr (std::same_as<T, double>)
    _mm_mask_i32scatter_ps(p, std::uint8_t(i.mask_), inds,
                           __builtin_bit_cast(__m128, x), 4);
  else if constexpr (sizeof(T) == 4)
    _mm_mask_i32scatter_epi32(p, std::uint8_t(i.mask_), inds,
                              __builtin_bit_cast(__m128i, x), 4);
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Bit<4> i, Vec<4, T> x,
                          std::int32_t stride) {
  scatter(p, i, x, range<4>() * stride);
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Bit<2> i,
                           Vec<2, std::int64_t> indv) -> Vec<2, T> {
  auto inds = __builtin_bit_cast(__m128i, indv);
  auto src{mmzero<2, T>()};
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(
      Vec<2, double>,
      _mm_mmask_i64gather_pd(src, std::uint8_t(i.mask_), inds, p, 8));
  else if constexpr (sizeof(T) == 8)
    return __builtin_bit_cast(
      Vec<2, T>,
      _mm_mmask_i64gather_epi64(src, std::uint8_t(i.mask_), inds, p, 8));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Bit<2> i, std::int32_t stride)
  -> Vec<2, T> {
  return gather(p, i, range<2>() * stride);
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::None<2>, Vec<2, T> x,
                            Vec<2, std::int64_t> indv) {
  auto inds = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    _mm_i64scatter_pd(p, inds, __builtin_bit_cast(__m128d, x), 8);
  else if constexpr (sizeof(T) == 8)
    _mm_i64scatter_epi64(p, inds, __builtin_bit_cast(__m128i, x), 8);
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::None<2>, Vec<2, T> x,
                          std::int32_t stride) {
  scatter(p, mask::None<2>{}, x, range<2>() * stride);
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::Bit<2> i, Vec<2, T> x,
                            Vec<2, std::int64_t> indv) {
  auto inds = __builtin_bit_cast(__m128i, indv);
  if constexpr (std::same_as<T, double>)
    _mm_mask_i64scatter_pd(p, std::uint8_t(i.mask_), inds,
                           __builtin_bit_cast(__m128d, x), 8);
  else if constexpr (sizeof(T) == 8)
    _mm_mask_i64scatter_epi64(p, std::uint8_t(i.mask_), inds,
                              __builtin_bit_cast(__m128i, x), 8);
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Bit<2> i, Vec<2, T> x,
                          std::int32_t stride) {
  scatter(p, i, x, range<2>() * stride);
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                          mask::Bit<W> m) {
  if constexpr (std::same_as<T, double>) {
    if constexpr (W == 8) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm512_mask3_fmadd_pd(__builtin_bit_cast(__m512d, a),
                                         __builtin_bit_cast(__m512d, b),
                                         __builtin_bit_cast(__m512d, c),
                                         std::uint8_t(m.mask_)));
    } else if constexpr (W == 4) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm256_mask3_fmadd_pd(__builtin_bit_cast(__m256d, a),
                                         __builtin_bit_cast(__m256d, b),
                                         __builtin_bit_cast(__m256d, c),
                                         std::uint8_t(m.mask_)));
    } else {
      static_assert(W == 2);
      return __builtin_bit_cast(
        Vec<W, T>, _mm_mask3_fmadd_pd(__builtin_bit_cast(__m128d, a),
                                      __builtin_bit_cast(__m128d, b),
                                      __builtin_bit_cast(__m128d, c),
                                      std::uint8_t(m.mask_)));
    }
  } else {
    static_assert(std::same_as<T, float>);
    if constexpr (W == 16) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm512_mask3_fmadd_ps(__builtin_bit_cast(__m512, a),
                                         __builtin_bit_cast(__m512, b),
                                         __builtin_bit_cast(__m512, c),
                                         std::uint16_t(m.mask_)));
    } else if constexpr (W == 8) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm256_mask3_fmadd_ps(__builtin_bit_cast(__m256, a),
                                         __builtin_bit_cast(__m256, b),
                                         __builtin_bit_cast(__m256, c),
                                         std::uint8_t(m.mask_)));
    } else {
      static_assert(W == 4);
      return __builtin_bit_cast(
        Vec<W, T>, _mm_mask3_fmadd_ps(__builtin_bit_cast(__m128, a),
                                      __builtin_bit_cast(__m128, b),
                                      __builtin_bit_cast(__m128, c),
                                      std::uint8_t(m.mask_)));
    }
  }
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fnmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                           mask::Bit<W> m) {
  if constexpr (std::same_as<T, double>) {
    if constexpr (W == 8) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm512_mask3_fnmadd_pd(__builtin_bit_cast(__m512d, a),
                                          __builtin_bit_cast(__m512d, b),
                                          __builtin_bit_cast(__m512d, c),
                                          std::uint8_t(m.mask_)));
    } else if constexpr (W == 4) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm256_mask3_fnmadd_pd(__builtin_bit_cast(__m256d, a),
                                          __builtin_bit_cast(__m256d, b),
                                          __builtin_bit_cast(__m256d, c),
                                          std::uint8_t(m.mask_)));
    } else {
      static_assert(W == 2);
      return __builtin_bit_cast(
        Vec<W, T>, _mm_mask3_fnmadd_pd(__builtin_bit_cast(__m128d, a),
                                       __builtin_bit_cast(__m128d, b),
                                       __builtin_bit_cast(__m128d, c),
                                       std::uint8_t(m.mask_)));
    }
  } else {
    static_assert(std::same_as<T, float>);
    if constexpr (W == 16) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm512_mask3_fnmadd_ps(__builtin_bit_cast(__m512, a),
                                          __builtin_bit_cast(__m512, b),
                                          __builtin_bit_cast(__m512, c),
                                          std::uint16_t(m.mask_)));
    } else if constexpr (W == 8) {
      return __builtin_bit_cast(
        Vec<W, T>, _mm256_mask3_fnmadd_ps(__builtin_bit_cast(__m256, a),
                                          __builtin_bit_cast(__m256, b),
                                          __builtin_bit_cast(__m256, c),
                                          std::uint8_t(m.mask_)));
    } else {
      static_assert(W == 4);
      return __builtin_bit_cast(
        Vec<W, T>, _mm_mask3_fnmadd_ps(__builtin_bit_cast(__m128, a),
                                       __builtin_bit_cast(__m128, b),
                                       __builtin_bit_cast(__m128, c),
                                       std::uint8_t(m.mask_)));
    }
  }
}
TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, double> x,
                              Vec<4, double> y) -> Vec<4, double> {
  return __builtin_bit_cast(Vec<4, double>,
                            _mm256_mask_mov_pd(__builtin_bit_cast(__m256d, y),
                                               std::uint8_t(m.mask_),
                                               __builtin_bit_cast(__m256d, x)));
}

TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, std::int64_t> x,
                              Vec<4, std::int64_t> y) -> Vec<4, std::int64_t> {
  return __builtin_bit_cast(
    Vec<4, std::int64_t>,
    _mm256_mask_mov_epi64(__builtin_bit_cast(__m256i, y), std::uint8_t(m.mask_),
                          __builtin_bit_cast(__m256i, x)));
}

TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, std::uint64_t> x,
                              Vec<4, std::uint64_t> y)
  -> Vec<4, std::uint64_t> {
  return __builtin_bit_cast(
    Vec<4, std::uint64_t>,
    _mm256_mask_mov_epi64(__builtin_bit_cast(__m256i, y), std::uint8_t(m.mask_),
                          __builtin_bit_cast(__m256i, x)));
}

TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, float> x, Vec<4, float> y)
  -> Vec<4, float> {
  return __builtin_bit_cast(Vec<4, float>,
                            _mm_mask_mov_ps(__builtin_bit_cast(__m128, y),
                                            std::uint8_t(m.mask_),
                                            __builtin_bit_cast(__m128, x)));
}

TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, std::int32_t> x,
                              Vec<4, std::int32_t> y) -> Vec<4, std::int32_t> {
  return __builtin_bit_cast(Vec<4, std::int32_t>,
                            _mm_mask_mov_epi32(__builtin_bit_cast(__m128i, y),
                                               std::uint8_t(m.mask_),
                                               __builtin_bit_cast(__m128i, x)));
}

TRIVIAL constexpr auto select(mask::Bit<4> m, Vec<4, std::uint32_t> x,
                              Vec<4, std::uint32_t> y)
  -> Vec<4, std::uint32_t> {
  return __builtin_bit_cast(Vec<4, std::uint32_t>,
                            _mm_mask_mov_epi32(__builtin_bit_cast(__m128i, y),
                                               std::uint8_t(m.mask_),
                                               __builtin_bit_cast(__m128i, x)));
}
TRIVIAL constexpr auto select(mask::Bit<2> m, Vec<2, double> x,
                              Vec<2, double> y) -> Vec<2, double> {
  return __builtin_bit_cast(Vec<2, double>,
                            _mm_mask_mov_pd(__builtin_bit_cast(__m128d, y),
                                            std::uint8_t(m.mask_),
                                            __builtin_bit_cast(__m128d, x)));
}

TRIVIAL constexpr auto select(mask::Bit<2> m, Vec<2, std::int64_t> x,
                              Vec<2, std::int64_t> y) -> Vec<2, std::int64_t> {
  return __builtin_bit_cast(Vec<2, std::int64_t>,
                            _mm_mask_mov_epi64(__builtin_bit_cast(__m128i, y),
                                               std::uint8_t(m.mask_),
                                               __builtin_bit_cast(__m128i, x)));
}

TRIVIAL constexpr auto select(mask::Bit<2> m, Vec<2, std::uint64_t> x,
                              Vec<2, std::uint64_t> y)
  -> Vec<2, std::uint64_t> {
  return __builtin_bit_cast(Vec<2, std::uint64_t>,
                            _mm_mask_mov_epi64(__builtin_bit_cast(__m128i, y),
                                               std::uint8_t(m.mask_),
                                               __builtin_bit_cast(__m128i, x)));
}

#else // No AVX512VL
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                          mask::Mask<W> m) {
  if constexpr ((W * sizeof(T)) != 64) return m.m ? (a * b + c) : c;
  else if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(
      Vec<W, T>, _mm512_mask3_fmadd_pd(__builtin_bit_cast(__m512d, a),
                                       __builtin_bit_cast(__m512d, b),
                                       __builtin_bit_cast(__m512d, c),
                                       std::uint8_t(m.mask_)));
  else if constexpr (std::same_as<T, float>)
    return __builtin_bit_cast(
      Vec<W, T>, _mm512_mask3_fmadd_ps(
                   __builtin_bit_cast(__m512, a), __builtin_bit_cast(__m512, b),
                   __builtin_bit_cast(__m512, c), std::uint16_t(m.mask_)));
  else static_assert(false);
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fnmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                           mask::Mask<W> m) {
  if constexpr ((W * sizeof(T)) != 64) return m.m ? (c - a * b) : c;
  else if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(
      Vec<W, T>, _mm512_mask3_fnmadd_pd(__builtin_bit_cast(__m512d, a),
                                        __builtin_bit_cast(__m512d, b),
                                        __builtin_bit_cast(__m512d, c),
                                        std::uint8_t(m.mask_)));
  else if constexpr (std::same_as<T, float>)
    return __builtin_bit_cast(
      Vec<W, T>, _mm512_mask3_fnmadd_ps(
                   __builtin_bit_cast(__m512, a), __builtin_bit_cast(__m512, b),
                   __builtin_bit_cast(__m512, c), std::uint16_t(m.mask_)));
  else static_assert(false);
}

// We need [gather, scatter, load, store] * [unmasked, masked]

// 128 bit fallback scatters
template <typename T>
TRIVIAL inline void store(T *p, mask::None<2>, Vec<2, T> x,
                          std::int32_t stride) {
  p[0] = x[0];
  p[stride] = x[1];
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::None<2>, Vec<2, T> x,
                            Vec<2, std::int64_t> i) {
  p[i[0]] = x[0];
  p[i[1]] = x[1];
}

template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<2, sizeof(T)> i, Vec<2, T> x,
                          std::int32_t stride) {
  if (i.m[0] != 0) p[0] = x[0];
  if (i.m[1] != 0) p[stride] = x[1];
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::Vector<2, sizeof(T)> i, Vec<2, T> x,
                            Vec<2, std::int64_t> indv) {
  if (i.m[0] != 0) p[indv[0]] = x[0];
  if (i.m[1] != 0) p[indv[1]] = x[1];
}

#ifdef __AVX512F__
#elifdef __AVX2__
// masked gathers
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<4, sizeof(T)> m,
                           Vec<4, std::int32_t> indv) -> Vec<4, T> {
  auto x = __builtin_bit_cast(__m128i, indv);
  static constexpr auto z = mmzero<4, T>();
  if constexpr (std::same_as<T, double>) {
    return __builtin_bit_cast(Vec<4, double>,
                              _mm256_mask_i32gather_pd(z, p, x, m, 8));
  } else if constexpr (sizeof(T) == 8) {
    const long long int *l = reinterpret_cast<const long long int *>(p);
    return __builtin_bit_cast(Vec<4, T>,
                              _mm256_mask_i32gather_epi64(z, l, x, m, 8));
  } else if constexpr (std::same_as<T, float>) {
    return __builtin_bit_cast(Vec<4, float>,
                              _mm_mask_i32gather_ps(z, p, x, m, 4));
  } else if constexpr (sizeof(T) == 4) {
    return __builtin_bit_cast(Vec<4, T>,
                              _mm_mask_i32gather_epi32(z, p, x, m, 4));
  } else static_assert(false);
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<4, sizeof(T)> m,
                           Vec<4, std::int64_t> indv) -> Vec<4, T> {
  auto x = __builtin_bit_cast(__m256i, indv);
  static constexpr auto z = mmzero<4, T>();
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(Vec<4, double>,
                              _mm256_mask_i64gather_pd(z, p, x, m, 8));
  else if constexpr (sizeof(T) == 8)
    return __builtin_bit_cast(Vec<4, T>,
                              _mm256_mask_i64gather_epi64(z, p, x, m, 8));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<4, sizeof(T)> m,
                         std::int32_t stride) -> Vec<4, T> {
  return gather(p, m, range<4>() * stride);
}
TRIVIAL inline auto gather(const double *p, mask::Vector<2, sizeof(double)> m,
                           Vec<2, std::int64_t> indv) -> Vec<2, double> {
  auto x = __builtin_bit_cast(__m128i, indv);
  __m128i mask = __m128i(m);
  static constexpr auto z = mmzero<2, double>();
  return __builtin_bit_cast(Vec<2, double>,
                            _mm_mask_i64gather_pd(z, p, x, mask, 8));
}

TRIVIAL inline auto gather(const std::int64_t *p,
                           mask::Vector<2, sizeof(std::int64_t)> m,
                           Vec<2, std::int64_t> indv) -> Vec<2, std::int64_t> {
  auto x = __builtin_bit_cast(__m128i, indv);
  __m128i mask = __m128i(m);
  static constexpr auto z = mmzero<2, std::int64_t>();
  return __builtin_bit_cast(Vec<2, std::int64_t>,
                            _mm_mask_i64gather_epi64(z, p, x, mask, 8));
}

TRIVIAL inline auto gather(const std::uint64_t *p,
                           mask::Vector<2, sizeof(std::uint64_t)> m,
                           Vec<2, std::int64_t> indv) -> Vec<2, std::uint64_t> {
  auto x = __builtin_bit_cast(__m128i, indv);
  __m128i mask = __m128i(m);
  static constexpr auto z = mmzero<2, std::uint64_t>();
  return __builtin_bit_cast(Vec<2, std::uint64_t>,
                            _mm_mask_i64gather_epi64(z, p, x, mask, 8));
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<2, sizeof(T)> m,
                         std::int32_t stride) -> Vec<2, T> {
  return gather(p, m, range<2>() * stride);
}

#else // no AVX2
// fallback 128-bit gather
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<2>, std::int32_t stride)
  -> Vec<2, T> {
  return Vec<2, T>{p[0], p[stride]};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<2>, Vec<2, std::int64_t> i)
  -> Vec<2, T> {
  return Vec<2, T>{p[i[0]], p[i[1]]};
}

template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<2, sizeof(T)> i,
                         std::int32_t stride) -> Vec<2, T> {
  return Vec<2, T>{(i.m[0] != 0) ? p[0] : T{}, (i.m[1] != 0) ? p[stride] : T{}};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<2, sizeof(T)> i,
                           Vec<2, std::int64_t> indv) -> Vec<2, T> {
  return Vec<2, T>{(i.m[0] != 0) ? p[indv[0]] : T{},
                   (i.m[1] != 0) ? p[indv[1]] : T{}};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<2, sizeof(T)> i,
                           Vec<2, std::int32_t> indv) -> Vec<2, T> {
  return Vec<2, T>{(i.m[0] != 0) ? p[indv[0]] : T{},
                   (i.m[1] != 0) ? p[indv[1]] : T{}};
}

template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<4>, std::int32_t stride)
  -> Vec<4, T> {
  return Vec<4, T>{p[0], p[stride], p[2 * stride], p[3 * stride]};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<4>, Vec<4, std::int32_t> i)
  -> Vec<4, T> {
  return Vec<4, T>{p[i[0]], p[i[1]], p[i[2]], p[i[3]]};
}

template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<4, sizeof(T)> i,
                         std::int32_t stride) -> Vec<4, T> {
  return Vec<4, T>{(i.m[0] != 0) ? p[0] : T{}, (i.m[1] != 0) ? p[stride] : T{},
                   (i.m[2] != 0) ? p[2 * stride] : T{},
                   (i.m[3] != 0) ? p[3 * stride] : T{}};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<4, sizeof(T)> i,
                           Vec<4, int> indv) -> Vec<4, T> {
  return Vec<4, T>{
    (i.m[0] != 0) ? p[indv[0]] : T{}, (i.m[1] != 0) ? p[indv[1]] : T{},
    (i.m[2] != 0) ? p[indv[2]] : T{}, (i.m[3] != 0) ? p[indv[3]] : T{}};
}

#ifdef __AVX__ // no AVX2, but AVX
// fallback 256-bit gather
template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<4>, std::int32_t stride)
  -> Vec<4, T> {
  return Vec<4, T>{p[0], p[stride], p[2 * stride], p[3 * stride]};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<4>, Vec<4, std::int32_t> i)
  -> Vec<4, T> {
  return Vec<4, T>{p[i[0]], p[i[1]], p[i[2]], p[i[3]]};
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::None<4>, Vec<4, std::int64_t> i)
  -> Vec<4, T> {
  return Vec<4, T>{p[i[0]], p[i[1]], p[i[2]], p[i[3]]};
}

template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<4, sizeof(T)> i,
                         std::int32_t stride) -> Vec<4, T> {
  return Vec<4, T>{
    (i.m[0] != 0) ? p[0] : T{},
    (i.m[1] != 0) ? p[stride] : T{},
    (i.m[2] != 0) ? p[2 * stride] : T{},
    (i.m[3] != 0) ? p[3 * stride] : T{},
  };
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<4, sizeof(T)> i,
                           Vec<4, std::int32_t> indv) -> Vec<4, T> {
  return Vec<4, T>{
    (i.m[0] != 0) ? p[indv[0]] : T{},
    (i.m[1] != 0) ? p[indv[1]] : T{},
    (i.m[2] != 0) ? p[indv[2]] : T{},
    (i.m[3] != 0) ? p[indv[3]] : T{},
  };
}
template <typename T>
TRIVIAL inline auto gather(const T *p, mask::Vector<4, sizeof(T)> i,
                           Vec<4, std::int64_t> indv) -> Vec<4, T> {
  return Vec<4, T>{
    (i.m[0] != 0) ? p[indv[0]] : T{},
    (i.m[1] != 0) ? p[indv[1]] : T{},
    (i.m[2] != 0) ? p[indv[2]] : T{},
    (i.m[3] != 0) ? p[indv[3]] : T{},
  };
}

#endif // AVX
#endif // no AVX2
#ifdef __AVX__
TRIVIAL inline auto load(const double *p, mask::Vector<4, sizeof(double)> i)
  -> Vec<4, double> {
  return __builtin_bit_cast(Vec<4, double>, _mm256_maskload_pd(p, i));
}

TRIVIAL inline auto load(const std::int64_t *p,
                         mask::Vector<4, sizeof(std::int64_t)> i)
  -> Vec<4, std::int64_t> {
  return __builtin_bit_cast(Vec<4, std::int64_t>,
                            _mm256_maskload_epi64((const long long *)p, i));
}

TRIVIAL inline auto load(const std::uint64_t *p,
                         mask::Vector<4, sizeof(std::uint64_t)> i)
  -> Vec<4, std::uint64_t> {
  return __builtin_bit_cast(Vec<4, std::uint64_t>,
                            _mm256_maskload_epi64((const long long *)p, i));
}

TRIVIAL inline auto load(const float *p, mask::Vector<4, sizeof(float)> i)
  -> Vec<4, float> {
  return __builtin_bit_cast(Vec<4, float>, _mm_maskload_ps(p, i));
}

TRIVIAL inline auto load(const std::int32_t *p,
                         mask::Vector<4, sizeof(std::int32_t)> i)
  -> Vec<4, std::int32_t> {
  return __builtin_bit_cast(Vec<4, std::int32_t>,
                            _mm_maskload_epi32((const int *)p, i));
}

TRIVIAL inline auto load(const std::uint32_t *p,
                         mask::Vector<4, sizeof(std::uint32_t)> i)
  -> Vec<4, std::uint32_t> {
  return __builtin_bit_cast(Vec<4, std::uint32_t>,
                            _mm_maskload_epi32((const int *)p, i));
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<8, sizeof(T)> i)
  -> Vec<8, T> {
  if constexpr (std::same_as<T, float>)
    return __builtin_bit_cast(Vec<8, float>, _mm256_maskload_ps(p, i));
  else if constexpr (sizeof(T) == 4)
    return __builtin_bit_cast(Vec<8, T>,
                              _mm256_maskload_epi32((const int *)p, i));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<4, sizeof(T)> i, Vec<4, T> x) {
  if constexpr (std::same_as<T, double>)
    _mm256_maskstore_pd(p, i, __builtin_bit_cast(__m256d, x));
  else if constexpr (sizeof(T) == 8)
    _mm256_maskstore_epi64((long long *)p, i, __builtin_bit_cast(__m256i, x));
  else if constexpr (std::same_as<T, float>)
    _mm_maskstore_ps(p, i, __builtin_bit_cast(__m128, x));
  else if constexpr (sizeof(T) == 4)
    _mm_maskstore_epi32((int *)p, i, __builtin_bit_cast(__m128i, x));
  else static_assert(false);
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<8, sizeof(T)> i, Vec<8, T> x) {
  if constexpr (std::same_as<T, float>)
    _mm256_maskstore_ps(p, i, __builtin_bit_cast(__m256, x));
  else if constexpr (sizeof(T) == 4)
    _mm256_maskstore_epi32((int *)p, i, __builtin_bit_cast(__m256i, x));
  else static_assert(false);
}

template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<2, sizeof(T)> i)
  -> Vec<2, T> {
  if constexpr (std::same_as<T, double>)
    return __builtin_bit_cast(Vec<2, double>, _mm_maskload_pd(p, i));
  else if constexpr (sizeof(T) == 8)
    return __builtin_bit_cast(Vec<2, T>,
                              _mm_maskload_epi64((const long long *)p, i));
  else static_assert(false);
}
TRIVIAL inline void store(double *p, mask::Vector<2, sizeof(double)> i,
                          Vec<2, double> x) {
  _mm_maskstore_pd(p, i, __builtin_bit_cast(__m128d, x));
}

TRIVIAL inline void store(std::int64_t *p,
                          mask::Vector<2, sizeof(std::int64_t)> i,
                          Vec<2, std::int64_t> x) {
  _mm_maskstore_epi64((long long *)p, i, __builtin_bit_cast(__m128i, x));
}

TRIVIAL inline void store(std::uint64_t *p,
                          mask::Vector<2, sizeof(std::uint64_t)> i,
                          Vec<2, std::uint64_t> x) {
  _mm_maskstore_epi64((long long *)p, i, __builtin_bit_cast(__m128i, x));
}

// we need 256 bit fallback scatters
template <typename T>
TRIVIAL inline void store(T *p, mask::None<4>, Vec<4, T> x,
                          std::int32_t stride) {
  p[0] = x[0];
  p[stride] = x[1];
  p[2 * stride] = x[2];
  p[3 * stride] = x[3];
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::None<4>, Vec<4, T> x,
                            Vec<4, std::int32_t> i) {
  p[i[0]] = x[0];
  p[i[1]] = x[1];
  p[i[2]] = x[2];
  p[i[3]] = x[3];
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<4, sizeof(T)> i, Vec<4, T> x,
                          std::int32_t stride) {
  if (i.m[0] != 0) p[0] = x[0];
  if (i.m[1] != 0) p[stride] = x[1];
  if (i.m[2] != 0) p[2 * stride] = x[2];
  if (i.m[3] != 0) p[3 * stride] = x[3];
}
template <typename T>
TRIVIAL inline void scatter(T *p, mask::Vector<4, sizeof(T)> i, Vec<4, T> x,
                            Vec<4, std::int32_t> indv) {
  if (i.m[0] != 0) p[indv[0]] = x[0];
  if (i.m[1] != 0) p[indv[1]] = x[1];
  if (i.m[2] != 0) p[indv[2]] = x[2];
  if (i.m[3] != 0) p[indv[3]] = x[3];
}
#else // No AVX
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<2, sizeof(T)> i)
  -> Vec<2, T> {
  return Vec<2, T>{(i.m[0] != 0) ? p[0] : T{}, (i.m[1] != 0) ? p[1] : T{}};
}
template <typename T>
TRIVIAL inline auto load(const T *p, mask::Vector<4, sizeof(T)> i)
  -> Vec<4, T> {
  return Vec<4, T>{(i.m[0] != 0) ? p[0] : T{}, (i.m[1] != 0) ? p[1] : T{},
                   (i.m[2] != 0) ? p[2] : T{}, (i.m[3] != 0) ? p[3] : T{}};
}

template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<2, sizeof(T)> i, Vec<2, T> x) {
  if (i.m[0] != 0) p[0] = x[0];
  if (i.m[1] != 0) p[1] = x[1];
}
template <typename T>
TRIVIAL inline void store(T *p, mask::Vector<4, sizeof(T)> i, Vec<4, T> x) {
  if (i.m[0] != 0) p[0] = x[0];
  if (i.m[1] != 0) p[1] = x[1];
  if (i.m[2] != 0) p[2] = x[2];
  if (i.m[3] != 0) p[3] = x[3];
}

#endif // No AVX
#endif // No AVX512VL
#ifdef __AVX__
TRIVIAL inline auto load(const double *p, mask::None<4>) -> Vec<4, double> {
  return __builtin_bit_cast(Vec<4, double>, _mm256_loadu_pd(p));
}

#ifdef __AVX512VL__
TRIVIAL inline auto load(const std::int64_t *p, mask::None<4>)
  -> Vec<4, std::int64_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<4, std::int64_t>, _mm256_loadu_epi64(vp));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::None<4>)
  -> Vec<4, std::uint64_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<4, std::uint64_t>, _mm256_loadu_epi64(vp));
}
#else
TRIVIAL inline auto load(const std::int64_t *p, mask::None<4>)
  -> Vec<4, std::int64_t> {
  const __m256i *pi = reinterpret_cast<const __m256i *>(p);
  return __builtin_bit_cast(Vec<4, std::int64_t>, _mm256_loadu_si256(pi));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::None<4>)
  -> Vec<4, std::uint64_t> {
  const __m256i *pi = reinterpret_cast<const __m256i *>(p);
  return __builtin_bit_cast(Vec<4, std::uint64_t>, _mm256_loadu_si256(pi));
}
#endif

TRIVIAL inline auto load(const float *p, mask::None<4>) -> Vec<4, float> {
  return __builtin_bit_cast(Vec<4, float>, _mm_loadu_ps(p));
}

#ifdef __AVX512VL__
TRIVIAL inline auto load(const std::int32_t *p, mask::None<4>)
  -> Vec<4, std::int32_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<4, std::int32_t>, _mm_loadu_epi32(vp));
}

TRIVIAL inline auto load(const std::uint32_t *p, mask::None<4>)
  -> Vec<4, std::uint32_t> {
  const void *vp = p;
  return __builtin_bit_cast(Vec<4, std::uint32_t>, _mm_loadu_epi32(vp));
}
#else
TRIVIAL inline auto load(const std::int32_t *p, mask::None<4>)
  -> Vec<4, std::int32_t> {
  const __m128i *pi = reinterpret_cast<const __m128i *>(p);
  return __builtin_bit_cast(Vec<4, std::int32_t>, _mm_loadu_si128(pi));
}

TRIVIAL inline auto load(const std::uint32_t *p, mask::None<4>)
  -> Vec<4, std::uint32_t> {
  const __m128i *pi = reinterpret_cast<const __m128i *>(p);
  return __builtin_bit_cast(Vec<4, std::uint32_t>, _mm_loadu_si128(pi));
}
#endif
TRIVIAL inline void store(double *p, mask::None<4>, Vec<4, double> x) {
  __m256d xd = __builtin_bit_cast(__m256d, x);
  _mm256_storeu_pd(p, xd);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(std::int64_t *p, mask::None<4>,
                          Vec<4, std::int64_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  void *vp = p;
  _mm256_storeu_epi64(vp, xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::None<4>,
                          Vec<4, std::uint64_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  void *vp = p;
  _mm256_storeu_epi64(vp, xi);
}
#else
TRIVIAL inline void store(std::int64_t *p, mask::None<4>,
                          Vec<4, std::int64_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  __m256i *pi = reinterpret_cast<__m256i *>(p);
  _mm256_storeu_si256(pi, xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::None<4>,
                          Vec<4, std::uint64_t> x) {
  __m256i xi = __builtin_bit_cast(__m256i, x);
  __m256i *pi = reinterpret_cast<__m256i *>(p);
  _mm256_storeu_si256(pi, xi);
}
#endif

TRIVIAL inline void store(float *p, mask::None<4>, Vec<4, float> x) {
  __m128 xf = __builtin_bit_cast(__m128, x);
  _mm_storeu_ps(p, xf);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(std::int32_t *p, mask::None<4>,
                          Vec<4, std::int32_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  void *vp = p;
  _mm_storeu_epi32(vp, xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::None<4>,
                          Vec<4, std::uint32_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  void *vp = p;
  _mm_storeu_epi32(vp, xi);
}
#else
TRIVIAL inline void store(std::int32_t *p, mask::None<4>,
                          Vec<4, std::int32_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  _mm_storeu_si128(pi, xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::None<4>,
                          Vec<4, std::uint32_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  _mm_storeu_si128(pi, xi);
}
#endif

// // non-power-of-2 memory ops
// template <std::ptrdiff_t N, typename M>
// constexpr auto fixupnonpow2(index::Vector<N, M> i) {
//   static_assert(std::popcount(std::size_t(N)) > 1,
//                 "Shouldn't be calling this if not needed.");
//   static constexpr std::ptrdiff_t W = std::bit_ceil(std::size_t(N));
//   auto m = i.mask_ & mask(index::VectorMask<W>{N});
//   return index::Vector<W, decltype(m)>{i.i, m};
// }

// template <typename T, std::ptrdiff_t N, typename M>
// TRIVIAL inline auto
// load(const T *p, index::Vector<N, M> i) {
//   return load(p, fixupnonpow2(i));
// }
// template <typename T, std::ptrdiff_t N, typename M>
// TRIVIAL inline auto
// load(const T *p, index::Vector<N, M> i, std::int32_t stride) {
//   return load(p, fixupnonpow2(i), stride);
// }
// template <typename T, std::ptrdiff_t N, typename M, std::ptrdiff_t W>
// TRIVIAL inline void
// store(T *p, index::Vector<N, M> i, Vec<W, T> x) {
//   store(p, fixupnonpow2(i), x);
// }
// template <typename T, std::ptrdiff_t N, typename M, std::ptrdiff_t W>
// TRIVIAL inline void
// store(T *p, index::Vector<N, M> i, Vec<W, T> x, std::int32_t stride) {
//   store(p, fixupnonpow2(i), stride);
// }
#else // NO AVX:

TRIVIAL inline auto load(const float *p, mask::None<4>) -> Vec<4, float> {
  return __builtin_bit_cast(Vec<4, float>, _mm_loadu_ps(p));
}

TRIVIAL inline auto load(const std::int32_t *p, mask::None<4>)
  -> Vec<4, std::int32_t> {
  return __builtin_bit_cast(Vec<4, std::int32_t>,
                            _mm_loadu_si128((const __m128i *)p));
}

TRIVIAL inline auto load(const std::uint32_t *p, mask::None<4>)
  -> Vec<4, std::uint32_t> {
  return __builtin_bit_cast(Vec<4, std::uint32_t>,
                            _mm_loadu_si128((const __m128i *)p));
}
TRIVIAL inline void store(float *p, mask::None<4>, Vec<4, float> x) {
  _mm_storeu_ps(p, __builtin_bit_cast(__m128d, x));
}

TRIVIAL inline void store(std::int32_t *p, mask::None<4>,
                          Vec<4, std::int32_t> x) {
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_si128(pi, xi);
}

TRIVIAL inline void store(std::uint32_t *p, mask::None<4>,
                          Vec<4, std::uint32_t> x) {
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  __m128i xi = __builtin_bit_cast(__m128i, x);
  _mm_storeu_si128(pi, xi);
}

#endif // AVX

TRIVIAL inline auto load(const double *p, mask::None<2>) -> Vec<2, double> {
  double const *dp = p;
  return __builtin_bit_cast(Vec<2, double>, _mm_loadu_pd(dp));
}

#ifdef __AVX512VL__
TRIVIAL inline auto load(const std::int64_t *p, mask::None<2>)
  -> Vec<2, std::int64_t> {
  return __builtin_bit_cast(Vec<2, std::int64_t>, _mm_loadu_epi64(p));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::None<2>)
  -> Vec<2, std::uint64_t> {
  return __builtin_bit_cast(Vec<2, std::uint64_t>, _mm_loadu_epi64(p));
}
#else
TRIVIAL inline auto load(const std::int64_t *p, mask::None<2>)
  -> Vec<2, std::int64_t> {
  return __builtin_bit_cast(Vec<2, std::int64_t>,
                            _mm_loadu_si128((const __m128i *)p));
}

TRIVIAL inline auto load(const std::uint64_t *p, mask::None<2>)
  -> Vec<2, std::uint64_t> {
  return __builtin_bit_cast(Vec<2, std::uint64_t>,
                            _mm_loadu_si128((const __m128i *)p));
}
#endif

template <typename T>
TRIVIAL inline auto load(const T *p, mask::None<2>) -> Vec<2, T> {
  return Vec<2, T>{p[0], p[1]};
}

TRIVIAL inline void store(double *p, mask::None<2>, Vec<2, double> x) {
  double *dp = p;
  __m128d xpd = __builtin_bit_cast(__m128d, x);
  _mm_storeu_pd(dp, xpd);
}

#ifdef __AVX512VL__
TRIVIAL inline void store(std::int64_t *p, mask::None<2>,
                          Vec<2, std::int64_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  void *vp = p;
  _mm_storeu_epi64(vp, xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::None<2>,
                          Vec<2, std::uint64_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  void *vp = p;
  _mm_storeu_epi64(vp, xi);
}
#else
TRIVIAL inline void store(std::int64_t *p, mask::None<2>,
                          Vec<2, std::int64_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  _mm_storeu_si128(pi, xi);
}

TRIVIAL inline void store(std::uint64_t *p, mask::None<2>,
                          Vec<2, std::uint64_t> x) {
  __m128i xi = __builtin_bit_cast(__m128i, x);
  __m128i *pi = reinterpret_cast<__m128i *>(p);
  _mm_storeu_si128(pi, xi);
}
#endif

template <typename T>
TRIVIAL inline void store(T *p, mask::None<2>, Vec<2, T> x) {
  *reinterpret_cast<Vec<2, T> *>(p) = x;
}

#ifdef __AVX512F__
// Compress store intrinsics for AVX512
template <typename T>
TRIVIAL inline void compressstore(T *p, mask::Bit<16> m, Vec<16, T> x) {
  if constexpr (std::same_as<T, float>) {
    _mm512_mask_compressstoreu_ps(p, std::uint16_t(m.mask_),
                                  __builtin_bit_cast(__m512, x));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    _mm512_mask_compressstoreu_epi32(p, std::uint16_t(m.mask_),
                                     __builtin_bit_cast(__m512i, x));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline auto expandload(const T *p, mask::Bit<16> m) -> Vec<16, T> {
  if constexpr (std::same_as<T, float>) {
    return __builtin_bit_cast(
      Vec<16, T>, _mm512_maskz_expandloadu_ps(std::uint16_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    return __builtin_bit_cast(
      Vec<16, T>, _mm512_maskz_expandloadu_epi32(std::uint16_t(m.mask_), p));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline void compressstore(T *p, mask::Bit<8> m, Vec<8, T> x) {
  if constexpr (std::same_as<T, double>) {
    _mm512_mask_compressstoreu_pd(p, std::uint8_t(m.mask_),
                                  __builtin_bit_cast(__m512d, x));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    _mm512_mask_compressstoreu_epi64(p, std::uint8_t(m.mask_),
                                     __builtin_bit_cast(__m512i, x));
  } else if constexpr (std::same_as<T, float>) {
    _mm256_mask_compressstoreu_ps(p, std::uint16_t(m.mask_),
                                  __builtin_bit_cast(__m256, x));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    _mm256_mask_compressstoreu_epi32(p, std::uint16_t(m.mask_),
                                     __builtin_bit_cast(__m256i, x));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline auto expandload(const T *p, mask::Bit<8> m) -> Vec<8, T> {
  if constexpr (std::same_as<T, double>) {
    return __builtin_bit_cast(
      Vec<8, T>, _mm512_maskz_expandloadu_pd(std::uint8_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    return __builtin_bit_cast(
      Vec<8, T>, _mm512_maskz_expandloadu_epi64(std::uint8_t(m.mask_), p));
  } else if constexpr (std::same_as<T, float>) {
    return __builtin_bit_cast(
      Vec<8, T>, _mm256_maskz_expandloadu_ps(std::uint16_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    return __builtin_bit_cast(
      Vec<8, T>, _mm256_maskz_expandloadu_epi32(std::uint16_t(m.mask_), p));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline void compressstore(T *p, mask::Bit<4> m, Vec<4, T> x) {
  if constexpr (std::same_as<T, double>) {
    _mm256_mask_compressstoreu_pd(p, std::uint8_t(m.mask_),
                                  __builtin_bit_cast(__m256d, x));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    _mm256_mask_compressstoreu_epi64(p, std::uint8_t(m.mask_),
                                     __builtin_bit_cast(__m256i, x));
  } else if constexpr (std::same_as<T, float>) {
    _mm128_mask_compressstoreu_ps(p, std::uint16_t(m.mask_),
                                  __builtin_bit_cast(__m128, x));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    _mm128_mask_compressstoreu_epi32(p, std::uint16_t(m.mask_),
                                     __builtin_bit_cast(__m128i, x));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline auto expandload(const T *p, mask::Bit<4> m) -> Vec<4, T> {
  if constexpr (std::same_as<T, double>) {
    return __builtin_bit_cast(
      Vec<4, T>, _mm256_maskz_expandloadu_pd(std::uint8_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    return __builtin_bit_cast(
      Vec<4, T>, _mm256_maskz_expandloadu_epi64(std::uint8_t(m.mask_), p));
  } else if constexpr (std::same_as<T, float>) {
    return __builtin_bit_cast(
      Vec<4, T>, _mm128_maskz_expandloadu_ps(std::uint16_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int32_t>) {
    return __builtin_bit_cast(
      Vec<4, T>, _mm128_maskz_expandloadu_epi32(std::uint16_t(m.mask_), p));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline void compressstore(T *p, mask::Bit<2> m, Vec<2, T> x) {
  if constexpr (std::same_as<T, double>) {
    _mm128_mask_compressstoreu_pd(p, std::uint8_t(m.mask_),
                                  __builtin_bit_cast(__m128d, x));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    _mm128_mask_compressstoreu_epi64(p, std::uint8_t(m.mask_),
                                     __builtin_bit_cast(__m128i, x));
  } else static_assert("type not supported");
}

template <typename T>
TRIVIAL inline auto expandload(const T *p, mask::Bit<2> m) -> Vec<2, T> {
  if constexpr (std::same_as<T, double>) {
    return __builtin_bit_cast(
      Vec<2, T>, _mm128_maskz_expandloadu_pd(std::uint8_t(m.mask_), p));
  } else if constexpr (std::same_as<T, std::int64_t>) {
    return __builtin_bit_cast(
      Vec<2, T>, _mm128_maskz_expandloadu_epi64(std::uint8_t(m.mask_), p));
  } else static_assert("type not supported");
}

#else
// Generic compress store/load for non-AVX512 or different widths
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void compressstore(T *p, std::uint64_t mask, Vec<W, T> x) {
  std::ptrdiff_t idx = 0;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (mask & (1ULL << w)) p[idx++] = x[w];
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto expandload(const T *p, std::uint64_t mask) -> Vec<W, T> {
  Vec<W, T> ret{};
  std::ptrdiff_t idx = 0;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (mask & (1ULL << w)) ret[w] = p[idx++];
  return ret;
}

#endif

#else // not __x86_64__

// Generic compress store/load for non-AVX512 or different widths
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void compressstore(T *p, std::uint64_t mask, Vec<W, T> x) {
  std::ptrdiff_t idx = 0;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (mask & (1ULL << w)) p[idx++] = x[w];
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto expandload(const T *p, std::uint64_t mask) -> Vec<W, T> {
  Vec<W, T> ret{};
  std::ptrdiff_t idx = 0;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (mask & (1ULL << w)) ret[w] = p[idx++];
  return ret;
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::None<W>) -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = p[w];
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::None<W>, Vec<W, T> x) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) p[w] = x[w];
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::Vector<W, 4> i) -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = (i.m[w] != 0) ? p[w] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::Vector<W, 8> i) -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = (i.m[w] != 0) ? p[w] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::Vector<W, 4> i, Vec<W, T> x) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (i.m[w] != 0) p[w] = x[w];
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::Vector<W, 8> i, Vec<W, T> x) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (i.m[w] != 0) p[w] = x[w];
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::None<W>, std::int32_t stride)
  -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = p[w * stride];
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto gather(const T *p, mask::None<W>, Vec<W, std::int32_t> indv)
  -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = p[indv[w]];
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto gather(const T *p, mask::None<W>, Vec<W, std::int64_t> indv)
  -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) ret[w] = p[indv[w]];
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::None<W>, Vec<W, T> x,
                          std::int32_t stride) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) p[w * stride] = x[w];
}
template <typename T, std::ptrdiff_t W, std::integral I>
TRIVIAL inline void scatter(T *p, mask::None<W>, Vec<W, T> x, Vec<W, I> indv) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w) p[indv[w]] = x[w];
}

template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::Vector<W, 4> i, std::int32_t stride)
  -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = (i.m[w] != 0) ? p[w * stride] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto load(const T *p, mask::Vector<W, 8> i, std::int32_t stride)
  -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = (i.m[w] != 0) ? p[w * stride] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto gather(const T *p, mask::Vector<W, sizeof(T)> i,
                           Vec<W, std::int32_t> indv) -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = (i.m[w] != 0) ? p[indv[w]] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto gather(const T *p, mask::Vector<W, sizeof(T)> i,
                           Vec<W, std::int64_t> indv) -> Vec<W, T> {
  Vec<W, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = (i.m[w] != 0) ? p[indv[w]] : T{};
  return ret;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::Vector<W, 4> i, Vec<W, T> x,
                          std::int32_t stride) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (i.m[w] != 0) p[w * stride] = x[w];
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline void store(T *p, mask::Vector<W, 8> i, Vec<W, T> x,
                          std::int32_t stride) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (i.m[w] != 0) p[w * stride] = x[w];
}
template <typename T, std::ptrdiff_t W, std::integral I>
TRIVIAL inline void scatter(T *p, mask::Vector<W, sizeof(T)> i, Vec<W, T> x,
                            Vec<W, I> indv) {
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t w = 0; w < W; ++w)
    if (i.m[w] != 0) p[indv[w]] = x[w];
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                          mask::Vector<W, sizeof(T)> m) {
  return m.m ? (a * b + c) : c;
}
template <typename T, std::ptrdiff_t W>
TRIVIAL inline auto fnmadd(Vec<W, T> a, Vec<W, T> b, Vec<W, T> c,
                           mask::Vector<W, sizeof(T)> m) {
  return m.m ? (c - a * b) : c;
}

#endif
#ifndef __AVX512F__
template <typename T, std::ptrdiff_t W>
TRIVIAL constexpr auto select(mask::Vector<W, sizeof(T)> m, Vec<W, T> x,
                              Vec<W, T> y) -> Vec<W, T> {
  return m.m ? x : y;
}
#endif
#ifdef __AVX512CD__

// count left zeros
template <std::ptrdiff_t W, std::integral T>
TRIVIAL inline constexpr auto clz(Vec<W, T> v) {
  static_assert((sizeof(T) == 4) || (sizeof(T) == 8));
  if constexpr (W == 16) {
    static_assert(sizeof(T) == 4);
    __m512i vi = __builtin_bit_cast(__m512i, v);
    return __builtin_bit_cast(Vec<W, T>, _mm512_lzcnt_epi32(vi));
  } else if constexpr (W == 8) {
    if constexpr (sizeof(T) == 8) {
      __m512i vi = __builtin_bit_cast(__m512i, v);
      return __builtin_bit_cast(Vec<W, T>, _mm512_lzcnt_epi64(vi));
    } else {
      __m256i vi = __builtin_bit_cast(__m256i, v);
      return __builtin_bit_cast(Vec<W, T>, _mm256_lzcnt_epi32(vi));
    }
  } else if constexpr (W == 4) {
    if constexpr (sizeof(T) == 8) {
      __m256i vi = __builtin_bit_cast(__m256i, v);
      return __builtin_bit_cast(Vec<W, T>, _mm256_lzcnt_epi64(vi));
    } else {
      __m128i vi = __builtin_bit_cast(__m128i, v);
      return __builtin_bit_cast(Vec<W, T>, _mm_lzcnt_epi32(vi));
    }
  } else {
    static_assert(sizeof(T) == 8);
    __m128i vi = __builtin_bit_cast(__m128i, v);
    return __builtin_bit_cast(Vec<W, T>, _mm_lzcnt_epi64(vi));
  }
}
// count right zeros
template <std::ptrdiff_t W, std::integral T>
TRIVIAL inline constexpr auto crz(Vec<W, T> v) {
  return T(8 * sizeof(T)) - clz<W, T>((~v) & (v - T(1)));
}

#else

template <std::ptrdiff_t W, std::integral T>
TRIVIAL constexpr auto clz(Vec<W, T> v) {
  Vec<W, T> ret;
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = T(std::countl_zero(std::make_unsigned_t<T>(v[w])));
  return ret;
}
template <std::ptrdiff_t W, std::integral T>
TRIVIAL constexpr auto crz(Vec<W, T> v) {
  Vec<W, T> ret;
  for (std::ptrdiff_t w = 0; w < W; ++w)
    ret[w] = T(std::countr_zero(std::make_unsigned_t<T>(v[w])));
  return ret;
}

#endif

template <typename T>
inline constexpr std::ptrdiff_t Width =
  SIMDSupported<T> ? VECTORWIDTH / sizeof(T) : 1;
template <std::ptrdiff_t N, typename T>
constexpr std::ptrdiff_t VecLen =
  (N < Width<T>) ? std::ptrdiff_t(std::bit_ceil(std::size_t(N)))
                 : std::max(Width<T>, std::ptrdiff_t(1));

// returns { vector_size, num_vectors, remainder }
template <std::ptrdiff_t L, typename T>
consteval auto VectorDivRem() -> std::array<std::ptrdiff_t, 3> {
  constexpr std::ptrdiff_t W = Width<T>;
  if constexpr (L <= W) {
    constexpr auto V = std::ptrdiff_t(std::bit_ceil(std::size_t(L)));
    return {V, L / V, L % V};
  } else return {W, L / W, L % W};
};
template <typename T, std::ptrdiff_t R, std::ptrdiff_t C>
TRIVIAL constexpr auto VecWidth() {
  if constexpr (C > 1) return VectorDivRem<C, T>()[0];
  else if constexpr (C == 1)
    if constexpr (R >= 1) return VectorDivRem<R, T>()[0];
    else return Width<T>;
  else return Width<T>;
}

template <typename T, typename I> consteval auto getWidth() -> std::ptrdiff_t {
  if constexpr (std::same_as<I, std::ptrdiff_t>) return simd::Width<T>;
  else return simd::VecLen<std::ptrdiff_t(I{}), T>;
}

namespace reduce {
template <std::ptrdiff_t W, typename T, typename Op>
TRIVIAL constexpr auto reduce_op(simd::Vec<W, T> v) -> T {
  if constexpr (W == 1) {
    return v;
  } else if constexpr (W == 2) {
    T lo = v[0], hi = v[1];
    return Op{}(lo, hi);
  } else if constexpr (W == 4) {
    Vec<2, T> lo = __builtin_shufflevector(v, v, 0, 1),
              hi = __builtin_shufflevector(v, v, 2, 3);
    return reduce_op<2, T, Op>(Op{}(lo, hi));
  } else if constexpr (W == 8) {
    Vec<4, T> lo = __builtin_shufflevector(v, v, 0, 1, 2, 3),
              hi = __builtin_shufflevector(v, v, 4, 5, 6, 7);
    return reduce_op<4, T, Op>(Op{}(lo, hi));
  } else if constexpr (W == 16) {
    Vec<8, T> lo = __builtin_shufflevector(v, v, 0, 1, 2, 3, 4, 5, 6, 7),
              hi = __builtin_shufflevector(v, v, 8, 9, 10, 11, 12, 13, 14, 15);
    return reduce_op<8, T, Op>(Op{}(lo, hi));
  } else {
    static_assert(false, "Unsupported vector width for reduction");
  }
}
template <std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto sum(simd::Vec<W, T> v) -> T {
  return reduce_op<W, T, std::plus<>>(v);
}
template <std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto prod(simd::Vec<W, T> v) -> T {
  return reduce_op<W, T, std::multiplies<>>(v);
}
} // namespace reduce

namespace index {
template <std::ptrdiff_t R, std::ptrdiff_t C = 1, std::ptrdiff_t W = 1,
          typename M = mask::None<W>, bool Transposed = false,
          std::ptrdiff_t X = -1>
struct UnrollDims {
  static_assert(W != 1 || std::same_as<M, mask::None<1>>,
                "Only mask vector dims");
  static_assert(W != 1 || !Transposed,
                "Canonicalize scalar with Tranpose=false");
  [[no_unique_address]] M mask_;
  [[no_unique_address]] math::RowStride<X> rs_;
};

template <typename T> inline constexpr bool issimd = false;

template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t W, typename M,
          bool Transposed, std::ptrdiff_t X>
inline constexpr bool issimd<UnrollDims<R, C, W, M, Transposed, X>> = true;

} // namespace index
template <class From, class To>
concept ConvertibleToAndScalar =
  std::convertible_to<From, To> && std::is_scalar_v<From>;
// template <typename T, std::ptrdiff_t W, typename S>
// TRIVIAL constexpr auto vcvt(Vec<W, S> v) {
//   if constexpr (std::same_as<T, S>) return v;
//   else if constexpr (W == 1) return T(v);
//   else return __builtin_convertvector(v, Vec<W, T>);
// }
// Vector goes across cols
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N, typename T>
struct Unroll {
  static constexpr std::ptrdiff_t W =
    std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
  using VT = El<W, T>;
  static_assert(R * C > 0);
  VT data_[R * C];
  TRIVIAL constexpr auto operator[](std::ptrdiff_t i) -> VT & {
    return data_[i];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t r, std::ptrdiff_t c)
    -> VT & {
    return data_[(r * C) + c];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t i) const -> VT {
    return data_[i];
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t r, std::ptrdiff_t c) const
    -> VT {
    return data_[(r * C) + c];
  }
  template <typename U>
  TRIVIAL constexpr operator Unroll<R, C, N, U>() const
    requires(!std::same_as<T, U>) {
    Unroll<R, C, N, U> x;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i)
      if constexpr (W == 1) x.data_[i] = U(data_[i]);
      else x.data_[i] = __builtin_convertvector(data_[i], Vec<W, U>);
    return x;
  }
  TRIVIAL constexpr auto operator-() {
    Unroll a;
    for (std::ptrdiff_t i = 0; i < R * C; ++i) a.data_[i] = -data_[i];
    return a;
  }
  TRIVIAL constexpr auto operator~() {
    Unroll a;
    for (std::ptrdiff_t i = 0; i < R * C; ++i) a.data_[i] = ~data_[i];
    return a;
  }
  TRIVIAL constexpr auto operator+=(const Unroll &a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] += a.data_[i];
    return *this;
  }
  TRIVIAL constexpr auto operator-=(const Unroll &a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] -= a.data_[i];
    return *this;
  }
  TRIVIAL constexpr auto operator*=(const Unroll &a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] *= a.data_[i];
    return *this;
  }
  TRIVIAL constexpr auto operator/=(const Unroll &a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] /= a.data_[i];
    return *this;
  }
  TRIVIAL constexpr auto operator+=(VT a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] += a;
    return *this;
  }
  TRIVIAL constexpr auto operator-=(VT a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] -= a;
    return *this;
  }
  TRIVIAL constexpr auto operator*=(VT a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] *= a;
    return *this;
  }
  TRIVIAL constexpr auto operator/=(VT a) -> Unroll & {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) data_[i] /= a;
    return *this;
  }
  TRIVIAL constexpr auto operator+=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    return (*this) += ::simd::vbroadcast<W, T>(a);
  }
  TRIVIAL constexpr auto operator-=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    return (*this) -= ::simd::vbroadcast<W, T>(a);
  }
  TRIVIAL constexpr auto operator*=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    return (*this) *= ::simd::vbroadcast<W, T>(a);
  }
  TRIVIAL constexpr auto operator/=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    return (*this) /= ::simd::vbroadcast<W, T>(a);
  }
  [[nodiscard]] TRIVIAL constexpr auto split() const requires(R == 1 || C == 1)
  {
    static_assert(R > 1 || C > 1);
    static constexpr std::ptrdiff_t Chalf = C >> 1;
    static constexpr std::ptrdiff_t Rhalf = R >> 1;
    static constexpr std::ptrdiff_t L = (R * C) >> 1;
    using U = std::conditional_t<R == 1, Unroll<1Z, Chalf, N, T>,
                                 Unroll<Rhalf, 1Z, N, T>>;

    if constexpr (L > 1) {
      std::array<U, 2> ret{};
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t i = 0; i < L; ++i) {
        ret[0].data_[i] = data_[i];
        ret[1].data_[i] = data_[i + L];
      }
      return ret;
    } else return std::array<U, 2>{U{data_[0]}, U{data_[1]}};
  }
  TRIVIAL static constexpr auto vbroadcast(T x) -> Unroll {
    Unroll u;
    static constexpr std::ptrdiff_t L = R * C;
    VT v = ::simd::vbroadcast<W>(x);
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < L; ++i) u.data_[i] = v;
    return u;
  }

private:
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator+(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::plus<>{});
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator-(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::minus<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator*(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::multiplies<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator/(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::divides<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator&(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::bit_and<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator|(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::bit_or<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator^(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::bit_xor<>{});
  }

  TRIVIAL friend constexpr auto operator==(Unroll a, T b) {

    return applyop<true>(a, Unroll::vbroadcast(b),
                         [](auto x, auto y) { return x == y; });
  }
  TRIVIAL friend constexpr auto operator!=(Unroll a, T b) {

    return applyop<true>(a, Unroll::vbroadcast(b),
                         [](auto x, auto y) { return x != y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator==(Unroll a,
                                           const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x == y; });
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator!=(Unroll a,
                                           const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x != y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator<(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x < y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator>(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x > y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator<=(Unroll a,
                                           const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x <= y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator>=(Unroll a,
                                           const Unroll<R1, C1, W1, T1> &b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x >= y; });
  }

  TRIVIAL friend constexpr auto operator+(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] + b;
    return c;
  }
  TRIVIAL friend constexpr auto operator-(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] - b;
    return c;
  }
  TRIVIAL friend constexpr auto operator*(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] * b;
    return c;
  }
  TRIVIAL friend constexpr auto operator/(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] / b;
    return c;
  }
  TRIVIAL friend constexpr auto operator&(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] & b;
    return c;
  }
  TRIVIAL friend constexpr auto operator|(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] | b;
    return c;
  }
  TRIVIAL friend constexpr auto operator^(Unroll a, VT b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a.data_[i] ^ b;
    return c;
  }
  TRIVIAL friend constexpr auto operator+(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a + ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator-(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a - ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator*(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a * ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator/(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a / ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator&(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a & ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator|(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a | ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator^(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a ^ ::simd::vbroadcast<W, T>(b);
  }

  TRIVIAL friend constexpr auto operator+(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a + b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator-(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a - b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator*(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a * b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator/(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a / b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator&(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a & b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator|(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a | b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator^(VT a, Unroll b) -> Unroll {
    Unroll<R, C, W, T> c;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < R * C; ++i) c.data_[i] = a ^ b.data_[i];
    return c;
  }
  TRIVIAL friend constexpr auto operator+(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) + a;
  }
  TRIVIAL friend constexpr auto operator-(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) - a;
  }
  TRIVIAL friend constexpr auto operator*(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) * a;
  }
  TRIVIAL friend constexpr auto operator/(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) / a;
  }
  TRIVIAL friend constexpr auto operator&(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) & a;
  }
  TRIVIAL friend constexpr auto operator|(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) | a;
  }
  TRIVIAL friend constexpr auto operator^(T b, Unroll a) -> Unroll
    requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) ^ a;
  }

  template <bool IsMask, std::ptrdiff_t R1, std::ptrdiff_t C1,
            std::ptrdiff_t W1, typename T1, typename Op>
  TRIVIAL friend constexpr auto applyop(Unroll a, Unroll<R1, C1, W1, T1> b,
                                        Op op) {
    // Possibilities:
    // 1. All match
    // 2. We had separate unrolls across rows and columns, and some arrays
    // were indexed by one or two of them.
    // In the latter case, we could have arrays indexed by rows, cols, or both.
    if constexpr (!std::same_as<T, T1>) {
      using PT = std::common_type_t<T, T1>;
      return applyop<IsMask>(Unroll<R, C, W, PT>(a), Unroll<R1, C1, W1, PT>(b),
                             op);
    } else if constexpr (W == W1) {
      // both were indexed by cols, and `C2`s should also match
      // or neither were, and they should still match.
      static_assert(C == C1);
      if constexpr (R == R1) {
        // Both have the same index across rows
        std::conditional_t<IsMask, mask::Unroll<R, C, W, sizeof(T)>,
                           Unroll<R, C, W, T>>
          c;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t i = 0; i < R * C; ++i)
          c.data_[i] = {op(a.data_[i], b.data_[i])};
        return c;
      } else if constexpr (R == 1) { // R1 > 0
        // `a` was indexed across cols only
        std::conditional_t<IsMask, mask::Unroll<R1, C, W, sizeof(T)>,
                           Unroll<R1, C, W, T>>
          z;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R1; ++r) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C; ++c)
            z[r, c] = {op(a.data_[c], b[r, c])};
        }
        return z;
      } else {
        static_assert(R1 == 1); // R > 0
        // `b` was indexed across cols only
        std::conditional_t<IsMask, mask::Unroll<R, C, W, sizeof(T)>,
                           Unroll<R, C, W, T>>
          z;
        if constexpr (C == 1) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t r = 0; r < R; ++r)
            z.data_[r] = {op(a.data_[r], b.vec_)};
        } else {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t r = 0; r < R; ++r) {
            POLYMATHFULLUNROLL
            for (std::ptrdiff_t c = 0; c < C; ++c)
              z[r, c] = {op(a[r, c], b.data_[c])};
          }
        }
        return z;
      }
    } else if constexpr (W == 1) {
      static_assert(R == 1 || C == 1);
      static constexpr std::ptrdiff_t R2 = R == 1 ? C : R;
      // `a` was indexed by row only
      std::conditional_t<IsMask, mask::Unroll<R2, C1, W1, sizeof(T)>,
                         Unroll<R2, C1, W1, T>>
        z;
      static_assert(R1 == R2 || R1 == 1);
      static_assert(R2 != 1);
      if constexpr (C1 == 1) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R2; ++r)
          if constexpr (R2 == R1) z.data_[r] = {op(a.data_[r], b.vec_[r])};
          else z.data_[r] = {op(a.data_[r], b.vec_)};
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R2; ++r) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C1; ++c)
            if constexpr (R2 == R1) z[r, c] = {op(a.data_[r], b[r, c])};
            else z[r, c] = {op(a.data_[r], b.data_[c])};
        }
      }
      return z;
    } else {
      static_assert(W1 == 1);
      static_assert(R1 == 1 || C1 == 1);
      constexpr std::ptrdiff_t R2 = R1 == 1 ? C1 : R1;
      // `b` was indexed by row only
      std::conditional_t<IsMask, mask::Unroll<R2, C, W, sizeof(T)>,
                         Unroll<R2, C, W, T>>
        z;
      static_assert(R == R2 || R == 1);
      if constexpr (R2 == 1) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          z.data_[c] = {op(a.data_[c], b.vec_)};
      } else if constexpr (C == 1) {
        static_assert(R != 1 && R == R2);
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R2; ++r)
          z.data_[r] = {op(a.data_[r], b.data_[r])};
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R2; ++r) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C; ++c)
            if constexpr (R == R2) z[r, c] = {op(a[r, c], b.data_[r])};
            else z[r, c] = {op(a.data_[c], b.data_[r])};
        }
      }
      return z;
    }
  }
};
template <std::ptrdiff_t N, typename T> struct Unroll<1, 1, N, T> {
  static constexpr std::ptrdiff_t W =
    std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
  using VT = El<W, T>;
  VT vec_;
  TRIVIAL constexpr auto operator[](std::ptrdiff_t) -> VT & { return vec_; }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t, std::ptrdiff_t) -> VT & {
    return vec_;
  }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t) const -> VT { return vec_; }
  TRIVIAL constexpr auto operator[](std::ptrdiff_t, std::ptrdiff_t) const
    -> VT {
    return vec_;
  }
  TRIVIAL constexpr operator VT() const { return vec_; }
  template <typename U>
  TRIVIAL constexpr operator Unroll<1, 1, N, U>() const
    requires(!std::same_as<T, U>) {
    if constexpr (W == 1) return {U(vec_)};
    else return {__builtin_convertvector(vec_, Vec<W, U>)};
  }
  TRIVIAL constexpr auto operator-() { return Unroll{-vec_}; }
  TRIVIAL constexpr auto operator~() { return Unroll{~vec_}; }
  TRIVIAL constexpr auto operator+=(const Unroll &a) -> Unroll & {
    vec_ += a.vec_;
    return *this;
  }
  TRIVIAL constexpr auto operator-=(const Unroll &a) -> Unroll & {
    vec_ -= a.vec_;
    return *this;
  }
  TRIVIAL constexpr auto operator*=(const Unroll &a) -> Unroll & {
    vec_ *= a.vec_;
    return *this;
  }
  TRIVIAL constexpr auto operator/=(const Unroll &a) -> Unroll & {
    vec_ /= a.vec_;
    return *this;
  }
  TRIVIAL constexpr auto operator+=(VT a) -> Unroll & {
    vec_ += a;
    return *this;
  }
  TRIVIAL constexpr auto operator-=(VT a) -> Unroll & {
    vec_ -= a;
    return *this;
  }
  TRIVIAL constexpr auto operator*=(VT a) -> Unroll & {
    vec_ *= a;
    return *this;
  }
  TRIVIAL constexpr auto operator/=(VT a) -> Unroll & {
    vec_ /= a;
    return *this;
  }
  TRIVIAL constexpr auto operator+=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    vec_ += ::simd::vbroadcast<W, T>(a);
    return *this;
  }
  TRIVIAL constexpr auto operator-=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    vec_ -= ::simd::vbroadcast<W, T>(a);
    return *this;
  }
  TRIVIAL constexpr auto operator*=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    vec_ *= ::simd::vbroadcast<W, T>(a);
    return *this;
  }
  TRIVIAL constexpr auto operator/=(std::convertible_to<T> auto a)
    -> Unroll & requires(W != 1) {
    vec_ /= ::simd::vbroadcast<W, T>(a);
    return *this;
  }
  [[nodiscard]] TRIVIAL constexpr auto split() const
    -> std::array<Unroll<1Z, 1Z, W / 2Z, T>, 2>
    requires(W == 2 || W == 4 || W == 8 || W == 16) {
    using U = Unroll<1Z, 1Z, W / 2Z, T>;
    auto s = ::simd::split(vec_);
    return std::array<U, 2>{U{s[0]}, U{s[1]}};
  }
  TRIVIAL static constexpr auto vbroadcast(T x) -> Unroll {
    return {::simd::vbroadcast<W>(x)};
  }

private:
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator+(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::plus<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator-(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<false>(a, b, std::minus<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator*(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::multiplies<>{});
  }

  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator/(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::divides<>{});
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator&(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::bit_and<>{});
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator|(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::bit_or<>{});
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator^(Unroll a,
                                          const Unroll<R1, C1, W1, T1> &b) {
    return applyop<false>(a, b, std::bit_xor<>{});
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator>(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x > y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator<(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x < y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator==(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x == y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator!=(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x != y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator>=(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x >= y; });
  }
  template <std::ptrdiff_t R1, std::ptrdiff_t C1, std::ptrdiff_t W1,
            typename T1>
  TRIVIAL friend constexpr auto operator<=(Unroll a, Unroll<R1, C1, W1, T1> b) {
    return applyop<true>(a, b, [](auto x, auto y) { return x <= y; });
  }

  TRIVIAL friend constexpr auto operator<(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::lt<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::gt<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator<=(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::le<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>=(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ge<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator==(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::eq<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator!=(Unroll a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ne<W, T>(a.vec_, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator<(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::lt<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator>(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::gt<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator<=(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::le<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator>=(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ge<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator==(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::eq<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator!=(Unroll a, VT b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ne<W, T>(a.vec_, b)};
  }
  TRIVIAL friend constexpr auto operator<(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::lt<W, T>(a, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::gt<W, T>(a, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator<=(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::le<W, T>(a, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>=(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ge<W, T>(a, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator==(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::eq<W, T>(a, b.vec_)};
  }
  TRIVIAL friend constexpr auto operator!=(VT a, Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ne<W, T>(a, b.vec_)};
  }

  TRIVIAL friend constexpr auto operator+(Unroll a, VT b) -> Unroll {
    return {a.vec_ + b};
  }
  TRIVIAL friend constexpr auto operator-(Unroll a, VT b) -> Unroll {
    return {a.vec_ - b};
  }
  TRIVIAL friend constexpr auto operator*(Unroll a, VT b) -> Unroll {
    return {a.vec_ * b};
  }
  TRIVIAL friend constexpr auto operator/(Unroll a, VT b) -> Unroll {
    return {a.vec_ / b};
  }
  TRIVIAL friend constexpr auto operator&(Unroll a, VT b) -> Unroll {
    return {a.vec_ & b};
  }
  TRIVIAL friend constexpr auto operator|(Unroll a, VT b) -> Unroll {
    return {a.vec_ | b};
  }
  TRIVIAL friend constexpr auto operator^(Unroll a, VT b) -> Unroll {
    return {a.vec_ ^ b};
  }
  TRIVIAL friend constexpr auto operator+(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a + ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator-(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a - ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator*(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a * ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator/(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a / ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator&(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a & ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator|(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a | ::simd::vbroadcast<W, T>(b);
  }
  TRIVIAL friend constexpr auto operator^(Unroll a,
                                          std::convertible_to<T> auto b)
    -> Unroll requires(W != 1) {
    return a ^ ::simd::vbroadcast<W, T>(b);
  }

  TRIVIAL friend constexpr auto operator+(VT a, Unroll b) -> Unroll {
    return {a + b.vec_};
  }
  TRIVIAL friend constexpr auto operator-(VT a, Unroll b) -> Unroll {
    return {a - b.vec_};
  }
  TRIVIAL friend constexpr auto operator*(VT a, Unroll b) -> Unroll {
    return {a * b.vec_};
  }
  TRIVIAL friend constexpr auto operator/(VT a, Unroll b) -> Unroll {
    return {a / b.vec_};
  }
  TRIVIAL friend constexpr auto operator&(VT a, Unroll b) -> Unroll {
    return {a & b.vec_};
  }
  TRIVIAL friend constexpr auto operator|(VT a, Unroll b) -> Unroll {
    return {a | b.vec_};
  }
  TRIVIAL friend constexpr auto operator^(VT a, Unroll b) -> Unroll {
    return {a ^ b.vec_};
  }
  TRIVIAL friend constexpr auto operator+(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) + a;
  }
  TRIVIAL friend constexpr auto operator-(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) - a;
  }
  TRIVIAL friend constexpr auto operator*(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) * a;
  }
  TRIVIAL friend constexpr auto operator/(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) / a;
  }
  TRIVIAL friend constexpr auto operator&(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) & a;
  }
  TRIVIAL friend constexpr auto operator|(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) | a;
  }
  TRIVIAL friend constexpr auto operator^(ConvertibleToAndScalar<T> auto b,
                                          Unroll a) -> Unroll requires(W != 1) {
    return ::simd::vbroadcast<W, T>(b) ^ a;
  }

  TRIVIAL friend constexpr auto operator<(Unroll a,
                                          std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::lt<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator>(Unroll a,
                                          std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::gt<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator<=(Unroll a,
                                           std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::le<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator>=(Unroll a,
                                           std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ge<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator==(Unroll a,
                                           std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::eq<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator!=(Unroll a,
                                           std::convertible_to<T> auto b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ne<W, T>(a.vec_, ::simd::vbroadcast<W, T>(b))};
  }
  TRIVIAL friend constexpr auto operator<(std::convertible_to<T> auto a,
                                          Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::lt<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>(std::convertible_to<T> auto a,
                                          Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::gt<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }
  TRIVIAL friend constexpr auto operator<=(std::convertible_to<T> auto a,
                                           Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::le<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }
  TRIVIAL friend constexpr auto operator>=(std::convertible_to<T> auto a,
                                           Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ge<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }
  TRIVIAL friend constexpr auto operator==(std::convertible_to<T> auto a,
                                           Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::eq<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }
  TRIVIAL friend constexpr auto operator!=(std::convertible_to<T> auto a,
                                           Unroll b)
    -> mask::Unroll<1, 1, N, sizeof(T)> {
    return {cmp::ne<W, T>(::simd::vbroadcast<W, T>(a), b.vec_)};
  }

  template <bool IsMask, std::ptrdiff_t R1, std::ptrdiff_t C1,
            std::ptrdiff_t W1, typename T1, typename Op>
  TRIVIAL friend constexpr auto applyop(Unroll a, Unroll<R1, C1, W1, T1> b,
                                        Op op) {
    // Possibilities:
    // 1. All match
    // 2. We had separate unrolls across rows and columns, and some arrays
    // were indexed by one or two of them.
    // In the latter case, we could have arrays indexed by rows, cols, or both.
    if constexpr (!std::same_as<T, T1>) {
      using PT = std::common_type_t<T, T1>;
      return applyop<IsMask>(Unroll<1, 1, W, PT>(a), Unroll<R1, C1, W1, PT>(b),
                             op);
    } else if constexpr (W == W1) {
      // both were indexed by cols, and `C`s should also match
      // or neither were, and they should still match.
      static_assert(C1 == 1);
      if constexpr (R1 != 1) {
        // `a` was indexed across cols only
        std::conditional_t<IsMask, mask::Unroll<R1, 1, W, sizeof(T)>,
                           Unroll<R1, 1, W, T>>
          z;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R1; ++r)
          z.data_[r] = op(a.vec_, b.data_[r]);
        return z;
      } else return Unroll<1, 1, W, T>{op(a.vec_, b.vec_)};
    } else if constexpr (W == 1) {
      // `a` was indexed by row only
      static_assert(R1 == 1);
      if constexpr (C1 != 1) {
        std::conditional_t<IsMask, mask::Unroll<1, C1, W1, sizeof(T)>,
                           Unroll<1, C1, W1, T>>
          z;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C1; ++c)
          z.data_[c] = op(a.vec_, b.data_[c]);
        return z;
      } else return Unroll<1, 1, W1, T>{op(a.vec_, b.vec_)};
    } else {
      static_assert(W1 == 1);
      static_assert(R1 == 1 || C1 == 1);
      constexpr std::ptrdiff_t R = R1 == 1 ? C1 : R1;
      // `b` was indexed by row only
      if constexpr (R != 1) {
        std::conditional_t<IsMask, mask::Unroll<R, 1, W, sizeof(T)>,
                           Unroll<R, 1, W, T>>
          z;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t r = 0; r < R; ++r)
          z.data_[r] = op(a.vec_, b.data_[r]);
        return z;
      } else return Unroll{op(a.vec_, b.vec_)};
    }
  }
};

template <std::ptrdiff_t C, std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto transpose(Unroll<1, C, W, T> u)
  -> Unroll<W * C, 1, 1, T> {
  Unroll<W * C, 1, 1, T> z;
  if constexpr (W == 1) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < C; ++i) z[i] = u[i];
  } else {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < C; ++i) {
      Vec<W, T> v{u[i]};
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t w = 0; w < W; ++w) z[w + (W * i)] = v[w];
    }
  }
  return z;
}

// 4 x 4C -> 4C x 4
template <std::ptrdiff_t R2, std::ptrdiff_t C, typename T>
TRIVIAL constexpr auto transpose(Unroll<R2, C, 2, T> u)
  -> Unroll<2 * C, R2 / VecLen<R2, T>, VecLen<R2, T>, T> requires(R2 % 2 == 0) {
  static constexpr std::ptrdiff_t V = VecLen<R2, T>;
  static constexpr std::ptrdiff_t R = R2 / V;
  Unroll<2 * C, R, V, T> z;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t zc = 0; zc < R; ++zc) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t zr = 0; zr < C; ++zr) {
      if constexpr (R2 % 8 == 0) {
        std::ptrdiff_t r8 = 8 * zc;
        Vec<2, T> a{u[r8, zr]}, b{u[r8 + 1, zr]}, c{u[r8 + 2, zr]},
          d{u[r8 + 3, zr]}, e{u[r8 + 4, zr]}, f{u[r8 + 5, zr]},
          g{u[r8 + 6, zr]}, h{u[r8 + 7, zr]};
        // inputs   a b c d e  f  g  h
        // returns: 0 2 4 6 8 10 12 14
        //          1 3 5 7 9 11 13 15
        Vec<4, T> i{__builtin_shufflevector(a, b, 0, 1, 2, 3)},
          j{__builtin_shufflevector(c, d, 0, 1, 2, 3)},
          k{__builtin_shufflevector(e, f, 0, 1, 2, 3)},
          l{__builtin_shufflevector(g, h, 0, 1, 2, 3)};
        Vec<8, T> m{__builtin_shufflevector(i, j, 0, 1, 2, 3, 4, 5, 6, 7)},
          n{__builtin_shufflevector(k, l, 0, 1, 2, 3, 4, 5, 6, 7)};
        z[2 * zr, zc] =
          __builtin_shufflevector(m, n, 0, 2, 4, 6, 8, 10, 12, 14);
        z[2 * zr + 1, zc] =
          __builtin_shufflevector(m, n, 1, 3, 5, 7, 9, 11, 13, 15);

      } else if constexpr (R2 % 4 == 0) {
        std::ptrdiff_t r4 = 4 * zc;
        Vec<2, T> a{u[r4, zr]}, b{u[r4 + 1, zr]}, c{u[r4 + 2, zr]},
          d{u[r4 + 3, zr]};
        // inputs:  a b c d
        // returns: 0 2 4 6
        //          1 3 5 7
        Vec<4, T> e{__builtin_shufflevector(a, b, 0, 1, 2, 3)},
          f{__builtin_shufflevector(c, d, 0, 1, 2, 3)};
        z[2 * zr, zc] = __builtin_shufflevector(e, f, 0, 2, 4, 6);
        z[2 * zr + 1, zc] = __builtin_shufflevector(e, f, 1, 3, 5, 7);

      } else {
        std::ptrdiff_t r2 = 2 * zc;
        Vec<2, T> a{u[r2, zr]}, b{u[r2 + 1, zr]};
        z[2 * zr, zc] = __builtin_shufflevector(a, b, 0, 2);
        z[2 * zr + 1, zc] = __builtin_shufflevector(a, b, 1, 3);
      }
    }
  }
  return z;
}
template <std::ptrdiff_t R2, std::ptrdiff_t C, typename T>
TRIVIAL constexpr auto transpose(Unroll<R2, C, 4, T> u)
  -> Unroll<4 * C, R2 / VecLen<R2, T>, VecLen<R2, T>, T> requires(R2 % 2 == 0) {
  static constexpr std::ptrdiff_t V = VecLen<R2, T>;
  static constexpr std::ptrdiff_t R = R2 / V;
  Unroll<4 * C, R, V, T> z;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t zc = 0; zc < R; ++zc) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t zr = 0; zr < C; ++zr) {
      if constexpr (R2 % 8 == 0) {
        std::ptrdiff_t c8 = 8 * zc;
        Vec<4, T> a{u[c8, zr]}, b{u[c8 + 1, zr]}, c{u[c8 + 2, zr]},
          d{u[c8 + 3, zr]}, e{u[c8 + 4, zr]}, f{u[c8 + 5, zr]},
          g{u[c8 + 6, zr]}, h{u[c8 + 7, zr]};
        // inputs   a b  c  d  e  f  g  h
        // returns: 0 4  8 12 16 20 24 28
        //          1 5  9 13 17 21 25 29
        //          2 6 10 14 18 22 26 30
        //          3 7 11 15 19 23 27 31
        Vec<8, T> i{__builtin_shufflevector(a, b, 0, 1, 2, 3, 4, 5, 6, 7)},
          j{__builtin_shufflevector(c, d, 0, 1, 2, 3, 4, 5, 6, 7)},
          k{__builtin_shufflevector(e, f, 0, 1, 2, 3, 4, 5, 6, 7)},
          l{__builtin_shufflevector(g, h, 0, 1, 2, 3, 4, 5, 6, 7)},
          m{__builtin_shufflevector(i, j, 0, 1, 4, 5, 8, 9, 12, 13)},
          n{__builtin_shufflevector(i, j, 2, 3, 6, 7, 10, 11, 14, 15)},
          o{__builtin_shufflevector(k, l, 0, 1, 4, 5, 8, 9, 12, 13)},
          p{__builtin_shufflevector(k, l, 2, 3, 6, 7, 10, 11, 14, 15)};
        z[4 * zr, zc] =
          __builtin_shufflevector(m, o, 0, 2, 4, 6, 8, 10, 12, 14);
        z[4 * zr + 1, zc] =
          __builtin_shufflevector(m, o, 1, 3, 5, 7, 9, 11, 13, 15);
        z[4 * zr + 2, zc] =
          __builtin_shufflevector(n, p, 0, 2, 4, 6, 8, 10, 12, 14);
        z[4 * zr + 3, zc] =
          __builtin_shufflevector(n, p, 1, 3, 5, 7, 9, 11, 13, 15);
      } else if constexpr (R2 % 4 == 0) {
        std::ptrdiff_t r4 = 4 * zc;
        Vec<4, T> a{u[r4, zr]}, b{u[r4 + 1, zr]}, c{u[r4 + 2, zr]},
          d{u[r4 + 3, zr]}, e{__builtin_shufflevector(a, b, 0, 1, 4, 5)},
          f{__builtin_shufflevector(a, b, 2, 3, 6, 7)},
          g{__builtin_shufflevector(c, d, 0, 1, 4, 5)},
          h{__builtin_shufflevector(c, d, 2, 3, 6, 7)};
        z[4 * zr, zc] = __builtin_shufflevector(e, g, 0, 2, 4, 6);
        z[4 * zr + 1, zc] = __builtin_shufflevector(e, g, 1, 3, 5, 7);
        z[4 * zr + 2, zc] = __builtin_shufflevector(f, h, 0, 2, 4, 6);
        z[4 * zr + 3, zc] = __builtin_shufflevector(f, h, 1, 3, 5, 7);
      } else {
        Vec<4, T> a{u[2 * zc, zr]}, b{u[2 * zc + 1, zr]},
          e{__builtin_shufflevector(a, b, 0, 4, 2, 6)},
          f{__builtin_shufflevector(a, b, 1, 5, 3, 7)};
        z[4 * zr, zc] = __builtin_shufflevector(e, e, 0, 1);
        z[4 * zr + 1, zc] = __builtin_shufflevector(f, f, 0, 1);
        z[4 * zr + 2, zc] = __builtin_shufflevector(e, e, 2, 3);
        z[4 * zr + 3, zc] = __builtin_shufflevector(f, f, 2, 3);
      }
    }
  }

  return z;
}
template <std::ptrdiff_t R2, std::ptrdiff_t C, typename T>
TRIVIAL constexpr auto transpose_droplast(Unroll<R2, C, 4, T> u)
  -> Unroll<3 * C, R2 / VecLen<R2, T>, VecLen<R2, T>, T> requires(R2 % 2 == 0) {
  static constexpr std::ptrdiff_t V = VecLen<R2, T>;
  static constexpr std::ptrdiff_t R = R2 / V;
  Unroll<3 * C, R, V, T> z;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t zc = 0; zc < R; ++zc) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t zr = 0; zr < C; ++zr) {
      if constexpr (R2 % 8 == 0) {
        std::ptrdiff_t c8 = 8 * zc;
        Vec<4, T> a{u[c8, zr]}, b{u[c8 + 1, zr]}, c{u[c8 + 2, zr]},
          d{u[c8 + 3, zr]}, e{u[c8 + 4, zr]}, f{u[c8 + 5, zr]},
          g{u[c8 + 6, zr]}, h{u[c8 + 7, zr]};
        // inputs   a b  c  d  e  f  g  h
        // returns: 0 4  8 12 16 20 24 28
        //          1 5  9 13 17 21 25 29
        //          2 6 10 14 18 22 26 30
        //          3 7 11 15 19 23 27 31
        Vec<8, T> i{__builtin_shufflevector(a, b, 0, 1, 2, 3, 4, 5, 6, 7)},
          j{__builtin_shufflevector(c, d, 0, 1, 2, 3, 4, 5, 6, 7)},
          k{__builtin_shufflevector(e, f, 0, 1, 2, 3, 4, 5, 6, 7)},
          l{__builtin_shufflevector(g, h, 0, 1, 2, 3, 4, 5, 6, 7)},
          m{__builtin_shufflevector(i, j, 0, 1, 4, 5, 8, 9, 12, 13)},
          n{__builtin_shufflevector(i, j, 2, 3, 6, 7, 10, 11, 14, 15)},
          o{__builtin_shufflevector(k, l, 0, 1, 4, 5, 8, 9, 12, 13)},
          p{__builtin_shufflevector(k, l, 2, 3, 6, 7, 10, 11, 14, 15)};
        z[3 * zr, zc] =
          __builtin_shufflevector(m, o, 0, 2, 4, 6, 8, 10, 12, 14);
        z[3 * zr + 1, zc] =
          __builtin_shufflevector(m, o, 1, 3, 5, 7, 9, 11, 13, 15);
        z[3 * zr + 2, zc] =
          __builtin_shufflevector(n, p, 0, 2, 4, 6, 8, 10, 12, 14);
      } else if constexpr (R2 % 4 == 0) {
        std::ptrdiff_t r4 = 4 * zc;
        Vec<4, T> a{u[r4, zr]}, b{u[r4 + 1, zr]}, c{u[r4 + 2, zr]},
          d{u[r4 + 3, zr]}, e{__builtin_shufflevector(a, b, 0, 1, 4, 5)},
          f{__builtin_shufflevector(a, b, 2, 3, 6, 7)},
          g{__builtin_shufflevector(c, d, 0, 1, 4, 5)},
          h{__builtin_shufflevector(c, d, 2, 3, 6, 7)};
        z[3 * zr, zc] = __builtin_shufflevector(e, g, 0, 2, 4, 6);
        z[3 * zr + 1, zc] = __builtin_shufflevector(e, g, 1, 3, 5, 7);
        z[3 * zr + 2, zc] = __builtin_shufflevector(f, h, 0, 2, 4, 6);
      } else {
        Vec<4, T> a{u[2 * zc, zr]}, b{u[2 * zc + 1, zr]},
          e{__builtin_shufflevector(a, b, 0, 4, 2, 6)},
          f{__builtin_shufflevector(a, b, 1, 5, 3, 7)};
        z[3 * zr, zc] = __builtin_shufflevector(e, e, 0, 1);
        z[3 * zr + 1, zc] = __builtin_shufflevector(f, f, 0, 1);
        z[3 * zr + 2, zc] = __builtin_shufflevector(e, e, 2, 3);
      }
    }
  }

  return z;
}
template <std::ptrdiff_t R8, std::ptrdiff_t C, typename T>
TRIVIAL constexpr auto transpose(Unroll<R8, C, 8, T> u)
  -> Unroll<8 * C, R8 / 8, 8, T> requires(R8 % 8 == 0) {
  static constexpr std::ptrdiff_t R = R8 / 8;
  Unroll<8 * C, R, 8, T> z;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t r = 0; r < R; ++r) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < C; ++i) {
      std::ptrdiff_t r8 = 8 * r, i8 = 8 * i;
      Vec<8, T> a{u[r8, i]}, b{u[r8 + 1, i]}, c{u[r8 + 2, i]}, d{u[r8 + 3, i]},
        e{u[r8 + 4, i]}, f{u[r8 + 5, i]}, g{u[r8 + 6, i]}, h{u[r8 + 7, i]},
        j{__builtin_shufflevector(a, b, 0, 8, 2, 10, 4, 12, 6, 14)},
        k{__builtin_shufflevector(a, b, 1, 9, 3, 11, 5, 13, 7, 15)},
        l{__builtin_shufflevector(c, d, 0, 8, 2, 10, 4, 12, 6, 14)},
        m{__builtin_shufflevector(c, d, 1, 9, 3, 11, 5, 13, 7, 15)},
        n{__builtin_shufflevector(e, f, 0, 8, 2, 10, 4, 12, 6, 14)},
        o{__builtin_shufflevector(e, f, 1, 9, 3, 11, 5, 13, 7, 15)},
        p{__builtin_shufflevector(g, h, 0, 8, 2, 10, 4, 12, 6, 14)},
        q{__builtin_shufflevector(g, h, 1, 9, 3, 11, 5, 13, 7, 15)};
      a = __builtin_shufflevector(j, l, 0, 1, 8, 9, 4, 5, 12, 13);
      b = __builtin_shufflevector(j, l, 2, 3, 10, 11, 6, 7, 14, 15);
      c = __builtin_shufflevector(k, m, 0, 1, 8, 9, 4, 5, 12, 13);
      d = __builtin_shufflevector(k, m, 2, 3, 10, 11, 6, 7, 14, 15);
      e = __builtin_shufflevector(n, p, 0, 1, 8, 9, 4, 5, 12, 13);
      f = __builtin_shufflevector(n, p, 2, 3, 10, 11, 6, 7, 14, 15);
      g = __builtin_shufflevector(o, q, 0, 1, 8, 9, 4, 5, 12, 13);
      h = __builtin_shufflevector(o, q, 2, 3, 10, 11, 6, 7, 14, 15);
      z[i8, r] = __builtin_shufflevector(a, e, 0, 1, 2, 3, 8, 9, 10, 11);
      z[i8 + 1, r] = __builtin_shufflevector(a, e, 4, 5, 6, 7, 12, 13, 14, 15);
      z[i8 + 2, r] = __builtin_shufflevector(b, f, 0, 1, 2, 3, 8, 9, 10, 11);
      z[i8 + 3, r] = __builtin_shufflevector(b, f, 4, 5, 6, 7, 12, 13, 14, 15);
      z[i8 + 4, r] = __builtin_shufflevector(c, g, 0, 1, 2, 3, 8, 9, 10, 11);
      z[i8 + 5, r] = __builtin_shufflevector(c, g, 4, 5, 6, 7, 12, 13, 14, 15);
      z[i8 + 6, r] = __builtin_shufflevector(d, h, 0, 1, 2, 3, 8, 9, 10, 11);
      z[i8 + 7, r] = __builtin_shufflevector(d, h, 4, 5, 6, 7, 12, 13, 14, 15);
    }
  }
  return z;
}

template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N, typename T,
          std::ptrdiff_t X, std::size_t NM = 1, typename MT = mask::None<N>>
TRIVIAL constexpr auto loadunroll(const T *ptr, math::RowStride<X> rowStride,
                                  std::array<MT, NM> masks)
  -> Unroll<R, C, N, T> requires(NM == 0 || NM == 1 || NM == C) {
  if constexpr (R * C == 1) {
    MT msk = masks[0];
    El<N, T> x = load(ptr, msk);
    return {x};
  } else {
    constexpr auto W = std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
    auto rs = std::ptrdiff_t(rowStride);
    Unroll<R, C, N, T> ret;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, ptr += rs) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          ret[r, c] = load(ptr + (c * W), mask::None<W>{});
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          ret[r, c] = load(ptr + (c * W), masks[c]);
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          ret[r, c] = load(ptr + (c * W), mask::None<W>{});
        ret[r, C - 1] = load(ptr + ((C - 1) * W), masks[0]);
      }
    }
    return ret;
  }
}
template <std::ptrdiff_t RC, std::ptrdiff_t RW, std::ptrdiff_t C,
          std::ptrdiff_t N, typename T, std::ptrdiff_t X, std::size_t NMR,
          std::size_t NMC, typename MTR, typename MTC>
TRIVIAL constexpr auto loadunrollmm(const T *ptr, math::RowStride<X> rowStride,
                                    std::array<MTR, NMR> row_masks,
                                    std::array<MTC, NMC> col_masks)
  -> Unroll<RC * RW, C, N, T>
  requires((NMC == 0 || NMC == 1 || NMC == C) &&
           ((NMR == 0) || (NMR == 1) || (NMR == RC))) {
  static constexpr std::ptrdiff_t R = RC * RW;
  if constexpr ((NMR == 0) || std::same_as<mask::None<RW>, MTR>) {
    return loadunroll<R, C, N>(ptr, rowStride, col_masks);
  } else if constexpr (R * C == 1) {
    El<N, T> x = row_masks[0].onEnd() ? load(ptr, col_masks[0]) : El<N, T>{};
    return {x};
  } else {
    constexpr auto W = std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
    // On NMR: if NMR > 1, then it equals R / O, where O is the transposes's W
    auto rs = std::ptrdiff_t(rowStride);
    Unroll<R, C, N, T> ret{};
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t rc = 0; rc < RC; ++rc, ptr += rs) {
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t rw = 0; rw < RW; ++rw, ptr += rs) {
        // here, we check whether we ought to continue or break
        if constexpr (NMR == RC) {
          // we mask
          if (rw >= row_masks[rc].onEnd()) break;
        } else {
          if ((rc + 1 == RC) && rw >= row_masks[0].onEnd()) break;
        }
        std::ptrdiff_t r = rw + (RW * rc);
        if constexpr (NMC == 0) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C; ++c)
            ret[r, c] = load(ptr + (c * W), mask::None<W>{});
        } else if constexpr (NMC == C) {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C; ++c)
            ret[r, c] = load(ptr + (c * W), col_masks[c]);
        } else {
          POLYMATHFULLUNROLL
          for (std::ptrdiff_t c = 0; c < C - 1; ++c)
            ret[r, c] = load(ptr + (c * W), mask::None<W>{});
          ret[r, C - 1] = load(ptr + ((C - 1) * W), col_masks[0]);
        }
      }
    }
    return ret;
  }
}
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N, typename T,
          std::ptrdiff_t X, std::size_t NM, typename MT = mask::None<N>>
TRIVIAL constexpr auto loadstrideunroll(const T *ptr,
                                        math::RowStride<X> rowStride,
                                        std::array<MT, NM> masks)
  -> Unroll<R, C, N, T> requires(NM == 0 || NM == 1 || NM == C) {
  auto s = std::int32_t(std::ptrdiff_t(rowStride));
  if constexpr (R * C == 1) return {load(ptr, masks[0], s)};
  else if constexpr (((R > 1) && ((R % N == 0) || (N % R == 0) ||
                                  ((R == 3) && (N > R))))) {
    static constexpr std::ptrdiff_t RL = C * N;
    static constexpr bool unmasked = NM == 0 || std::same_as<MT, mask::None<N>>;
    if constexpr (R != 3) {
      static constexpr std::ptrdiff_t CL = R > N ? R / N : 1;
      static constexpr std::ptrdiff_t WL = R > N ? N : R;
      if constexpr (unmasked) {
        return transpose(loadunroll<RL, CL, WL>(
          ptr, rowStride, std::array<mask::None<WL>, 0>{}));

      } else {
        return transpose(loadunrollmm<C, N, CL, WL>(
          ptr, rowStride, masks, std::array<mask::None<WL>, 0>{}));
      }
    } else if constexpr (unmasked) {
      // NOTE: NM == 1 == C, so we only need to pass a 1-element mask
      return transpose_droplast(loadunroll<RL, 1, 4>(
        ptr, rowStride, std::array{mask::create<4>(0, 3)}));

    } else {
      // NOTE: NM == 1 == C, so we only need to pass a 1-element mask
      return transpose_droplast(loadunrollmm<C, N, 1, 4>(
        ptr, rowStride, masks, std::array{mask::create<4>(0, 3)}));
    }
  } else {
    constexpr auto W = std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
    Unroll<R, C, N, T> ret;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, ++ptr) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          ret[r, c] = load(ptr + c * W * s, mask::None<W>{}, s);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          ret[r, c] = load(ptr + c * W * s, masks[c], s);
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          ret[r, c] = load(ptr + c * W * s, mask::None<W>{}, s);
        ret[r, C - 1] = load(ptr + (C - 1) * W * s, masks[0], s);
      }
    }
    return ret;
  }
}

// Represents a reference for a SIMD load, in particular so that we can store.
// Needs to support masking
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N, typename T,
          std::ptrdiff_t X, std::ptrdiff_t NM, typename MT = mask::None<N>,
          bool Transposed = false>
struct UnrollRef {
  static constexpr std::ptrdiff_t W =
    std::ptrdiff_t(std::bit_ceil(std::size_t(N)));
  static_assert(N == W || C == 1,
                "If N != the next power of `2`, then `C` should be `1`");
  static_assert(
    NM == 0 || NM == 1 || NM == C,
    "Should have no masks, one mask for last `C`, or one mask per `C`");
  using UT = Unroll<R, C, N, T>;
  T *ptr_;
  [[no_unique_address]] math::RowStride<X> row_stride_;
  [[no_unique_address]] std::array<MT, NM> masks_;
  TRIVIAL constexpr operator UT() {
    if constexpr (!Transposed)
      return loadunroll<R, C, N, T, X, NM, MT>(ptr_, row_stride_, masks_);
    else
      return loadstrideunroll<R, C, N, T, X, NM, MT>(ptr_, row_stride_, masks_);
  }
  TRIVIAL constexpr auto operator=(UT x) -> UnrollRef & requires(!Transposed) {
    auto rs = std::ptrdiff_t(row_stride_);
    T *p = ptr_;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, p += rs) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + (c * W), mask::None<W>{}, x[r, c]);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c) {
          auto msk = masks_[c];
          store(p + c * W, msk, x[r, c]);
          // store(p + c * W, masks[c], x[r, c]);
        }
      } else { // NM == 1
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W, mask::None<W>{}, x[r, c]);
        store(p + (C - 1) * W, masks_[0], x[r, C - 1]);
      }
    }
    return *this;
  }
  TRIVIAL constexpr auto operator=(Unroll<1, C, N, T> x)
    -> UnrollRef & requires((!Transposed) && (R != 1)) {
    auto rs = std::ptrdiff_t(row_stride_);
    T *p = ptr_;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, p += rs) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W, mask::None<W>{}, x[0, c]);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c) {
          auto msk = masks_[c];
          store(p + c * W, msk, x[0, c]);
        }
      } else { // NM == 1
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W, mask::None<W>{}, x[0, c]);
        store(p + (C - 1) * W, masks_[0], x[0, C - 1]);
      }
    }
    return *this;
  }
  TRIVIAL constexpr auto operator=(Unroll<R, C, 1, T> x)
    -> UnrollRef & requires(!Transposed && (N != 1)) {
    auto rs = std::ptrdiff_t(row_stride_);
    T *p = ptr_;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, p += rs) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W, mask::None<W>{}, vbroadcast<W>(x[r, c]));
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W, masks_[c], vbroadcast<W>(x[r, c]));
      } else { // NM == 1
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W, mask::None<W>{}, vbroadcast<W>(x[r, c]));
        store(p + (C - 1) * W, masks_[0], vbroadcast<W>(x[r, C - 1]));
      }
    }
    return *this;
  }

  TRIVIAL constexpr auto operator=(El<W, T> v)
    -> UnrollRef & requires(!Transposed) {
    auto rs = std::ptrdiff_t(row_stride_);
    T *p = ptr_;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t r = 0; r < R; ++r, p += rs) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W, mask::None<W>{}, v);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c) store(p + c * W, masks_[c], v);
      } else { // NM == 1
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W, mask::None<W>{}, v);
        store(p + (C - 1) * W, masks_[0], v);
      }
    }
    return *this;
  }
  TRIVIAL constexpr auto operator=(Unroll<R, C, N, T> x)
    -> UnrollRef & requires(Transposed) {
    auto s = std::int32_t(std::ptrdiff_t(row_stride_));
    T *p = ptr_;
    for (std::ptrdiff_t r = 0; r < R; ++r, ++p) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W * s, mask::None<W>{}, x[0, c], s);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W * s, masks_[c], x[0, c], s);
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W * s, mask::None<W>{}, x[0, c], s);
        store(p + (C - 1) * W * s, masks_[0], x[0, C - 1], s);
      }
    }
    return *this;
  }
  TRIVIAL constexpr auto operator=(El<W, T> v)
    -> UnrollRef & requires(Transposed) {
    auto s = std::int32_t(std::ptrdiff_t(row_stride_));
    T *p = ptr_;
    for (std::ptrdiff_t r = 0; r < R; ++r, ++p) {
      if constexpr (NM == 0) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W * s, mask::None<W>{}, v, s);
      } else if constexpr (NM == C) {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C; ++c)
          store(p + c * W * s, masks_[c], v, s);
      } else {
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t c = 0; c < C - 1; ++c)
          store(p + c * W * s, mask::None<W>{}, v, s);
        store(p + (C - 1) * W * s, masks_[0], v, s);
      }
    }
    return *this;
  }
  TRIVIAL constexpr auto operator=(std::convertible_to<T> auto x)
    -> UnrollRef & {
    static_assert(!std::same_as<T, long> ||
                  (W == 1 || W == 2 || W == 4 || W == 8));
    *this = El<W, T>{} + T(x);
    return *this;
  }
  TRIVIAL constexpr auto operator+=(const auto &x) -> UnrollRef & {
    return (*this) = Unroll<R, C, N, T>(*this) + x;
  }
  TRIVIAL constexpr auto operator-=(const auto &x) -> UnrollRef & {
    return (*this) = Unroll<R, C, N, T>(*this) - x;
  }
  TRIVIAL constexpr auto operator*=(const auto &x) -> UnrollRef & {
    return (*this) = Unroll<R, C, N, T>(*this) * x;
  }
  TRIVIAL constexpr auto operator/=(const auto &x) -> UnrollRef & {
    return (*this) = Unroll<R, C, N, T>(*this) / x;
  }
  TRIVIAL constexpr auto operator+(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) + x;
  }
  TRIVIAL constexpr auto operator-(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) - x;
  }
  TRIVIAL constexpr auto operator*(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) * x;
  }
  TRIVIAL constexpr auto operator/(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) / x;
  }
  TRIVIAL constexpr auto operator&(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) & x;
  }
  TRIVIAL constexpr auto operator|(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) | x;
  }
  TRIVIAL constexpr auto operator^(const auto &x) -> simd::Unroll<R, C, N, T> {
    return simd::Unroll<R, C, N, T>(*this) ^ x;
  }
  TRIVIAL constexpr auto operator>(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) > x;
  }
  TRIVIAL constexpr auto operator<(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) < x;
  }
  TRIVIAL constexpr auto operator>=(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) >= x;
  }
  TRIVIAL constexpr auto operator<=(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) <= x;
  }
  TRIVIAL constexpr auto operator==(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) == x;
  }
  TRIVIAL constexpr auto operator!=(const auto &x) {
    return simd::Unroll<R, C, N, T>(*this) != x;
  }
};
template <typename T, std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t W,
          typename M, bool Transposed, std::ptrdiff_t X>
TRIVIAL constexpr auto ref(const T *p,
                           index::UnrollDims<R, C, W, M, Transposed, X> i)
  -> Unroll<R, C, W, T> {
  if constexpr (Transposed)
    return loadstrideunroll<R, C, W>(p, i.rs_, std::array<M, 1>{i.mask_});
  else return loadunroll<R, C, W>(p, i.rs_, std::array<M, 1>{i.mask_});
}
template <typename T, std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t W,
          typename M, bool Transposed, std::ptrdiff_t X>
TRIVIAL constexpr auto ref(T *p, index::UnrollDims<R, C, W, M, Transposed, X> i)
  -> UnrollRef<R, C, W, T, X, 1, M, Transposed> {
  return {p, i.rs_, std::array<M, 1>{i.mask_}};
}

namespace index {
// Unroll rows by a factor of `R` and cols by `C`, vectorizing with width `W`
template <std::ptrdiff_t U, std::ptrdiff_t W = 1, typename M = mask::None<W>>
struct Unroll {
  std::ptrdiff_t index_;
  [[no_unique_address]] M mask_{};
  TRIVIAL explicit constexpr operator std::ptrdiff_t() const { return index_; }
  TRIVIAL explicit constexpr operator bool() const { return mask_.any(); }

  template <std::integral I>
  TRIVIAL constexpr operator ::simd::Unroll<1, U, W, I>() const {
    if constexpr (U != 1) {
      ::simd::Unroll<1, U, W, I> ret;
      El<W, I> r{::simd::range<W, I>()},
        ind = vbroadcast<W>(static_cast<I>(index_));
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u) ret.data_[u] = r + ind + (W * u);
      return ret;
    } else return {::simd::range<W, I>() + index_};
  }
#ifdef __AVX512F__
  template <std::ptrdiff_t S>
  TRIVIAL constexpr auto sub() requires(std::same_as<M, mask::Bit<W>>) {
    static_assert((S <= W) && (U == 1));
    Unroll<1, S, mask::Bit<S>> u{index_, mask_.template sub<S>()};
    index_ += S;
    return u;
  }
#endif

private:
  TRIVIAL friend constexpr auto operator+(Unroll a, std::ptrdiff_t b)
    -> Unroll {
    return {b + a.index_, a.mask_};
  }
  TRIVIAL friend constexpr auto operator==(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u)
          ret.data[u] = (x.index_ + u) == y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ == y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() == (v - u * W);
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() == vbroadcast<W, std::int64_t>(y - x.index_)};
  }
  TRIVIAL friend constexpr auto operator!=(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u)
          ret.data[u] = (x.index_ + u) != y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ != y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() != (v - u * W);
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() != vbroadcast<W, std::int64_t>(y - x.index_)};
  }

  TRIVIAL friend constexpr auto operator<(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u) ret.data[u] = (x.index_ + u) < y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ < y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() < (v - u * W);
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() < vbroadcast<W, std::int64_t>(y - x.index_)};
  }

  TRIVIAL friend constexpr auto operator>(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u) ret.data[u] = (x.index_ + u) > y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ > y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() > (v - u * W);
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() > vbroadcast<W, std::int64_t>(y - x.index_)};
  }

  TRIVIAL friend constexpr auto operator<=(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u)
          ret.data[u] = (x.index_ + u) <= y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ <= y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() <= (v - (u * W));
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() <= vbroadcast<W, std::int64_t>(y - x.index_)};
  }

  TRIVIAL friend constexpr auto operator>=(Unroll x, std::ptrdiff_t y) {
    if constexpr (W == 1) {
      if constexpr (U > 1) {
        ::simd::Unroll<U, 1, 1, std::int64_t> ret;
        POLYMATHFULLUNROLL
        for (std::ptrdiff_t u = 0; u < U; ++u)
          ret.data[u] = (x.index_ + u) >= y;
        return ret;
      } else return ::simd::Unroll<1, 1, W, std::int64_t>{x.index_ >= y};
    } else if constexpr (U > 1) {
      ::simd::Unroll<1, U, W, std::int64_t> ret;
      El<W, std::int64_t> v = vbroadcast<W, std::int64_t>(y - x.index_);
      POLYMATHFULLUNROLL
      for (std::ptrdiff_t u = 0; u < U; ++u)
        ret.data[u] = range<W, std::int64_t>() >= (v - (u * W));
      return ret;
    } else
      return ::simd::Unroll<1, 1, W, std::int64_t>{
        range<W, std::int64_t>() >= vbroadcast<W, std::int64_t>(y - x.index_)};
  }
};
template <std::ptrdiff_t U, std::ptrdiff_t W>
TRIVIAL constexpr auto unrollmask(std::ptrdiff_t L, std::ptrdiff_t i) {
  // mask applies to last iter
  // We can't check that the last iter is non-empty, because that
  // could be the loop exit condition
  auto m{mask::create<W>(i + ((U - 1) * W), L)};
  return Unroll<U, W, decltype(m)>{i, m};
};
#ifdef __AVX512VL__
template <std::ptrdiff_t W>
TRIVIAL constexpr auto tailmask(std::ptrdiff_t i, std::ptrdiff_t m)
  -> Unroll<1, W, mask::Bit<W>> {
  return {i, mask::createSmallPositive<W>(m)};
}
#else
template <std::ptrdiff_t W>
TRIVIAL constexpr auto tailmask(std::ptrdiff_t i, std::ptrdiff_t m) {
  auto mask{mask::create<W>(i, i + m)};
  return Unroll<1, W, decltype(mask)>{i, mask};
}
#endif
template <std::ptrdiff_t U, std::ptrdiff_t W, typename M>
inline constexpr bool issimd<Unroll<U, W, M>> = true;
} // namespace index

namespace mask {
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N,
          std::size_t Bytes>
template <typename T>
constexpr auto
Unroll<R, C, N, Bytes>::select(const ::simd::Unroll<R, C, N, T> &x,
                               const ::simd::Unroll<R, C, N, T> &y)
  -> ::simd::Unroll<R, C, N, T> {
  ::simd::Unroll<R, C, N, T> ret;
  POLYMATHFULLUNROLL
  for (std::ptrdiff_t r = 0; r < R; ++r) {
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t c = 0; c < C; ++c) {
      std::ptrdiff_t i = (r * C) + c;
      ret.data_[i] = ::simd::select(data_[i], x.data_[i], y.data_[i]);
    }
  }
  return ret;
}
template <std::ptrdiff_t R, std::ptrdiff_t C, std::ptrdiff_t N,
          std::size_t Bytes>
template <typename T, std::ptrdiff_t CU, std::ptrdiff_t W>
[[nodiscard]] TRIVIAL constexpr auto
Unroll<R, C, N, Bytes>::select(const ::simd::Unroll<R, CU, W, T> &x,
                               const ::simd::Unroll<R, CU, W, T> &y)
  -> ::simd::Unroll<R, CU, W, T> requires((CU * W == C * N) && (CU != C)) {
  if constexpr (C < CU) {
    // We will double `C` and cut `N` in half.
    static constexpr std::ptrdiff_t C2 = C << 1;
    static constexpr std::ptrdiff_t Nhalf = N >> 1;
    static constexpr std::ptrdiff_t L = R * C;
    Unroll<R, C2, Nhalf, Bytes> s;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < L; ++i) {
      auto splt = data_[i].split();
      s.data_[2 * i] = splt[0], s.data_[(2 * i) + 1] = splt[1];
    }
    // either `s` matches, or continues the recursion
    return s.select(x, y);
  } else { // C > CU
    // We will double `CU` and cut `W` in half.
    static constexpr std::ptrdiff_t C2 = CU << 1;
    static constexpr std::ptrdiff_t Whalf = W >> 1;
    static constexpr std::ptrdiff_t L = R * CU;
    ::simd::Unroll<R, C2, Whalf, T> a, b;
    POLYMATHFULLUNROLL
    for (std::ptrdiff_t i = 0; i < L; ++i) {
      auto xsplt = x.data_[i].split();
      auto ysplt = y.data_[i].split();
      a.data_[2 * i] = xsplt[0], a.data_[(2 * i) + 1] = xsplt[1];
      b.data_[2 * i] = ysplt[0], b.data_[(2 * i) + 1] = ysplt[1];
    }
    // either matches, or continues the recursion
    return select(a, b);
  }
}
template <std::ptrdiff_t N, std::size_t Bytes>
template <typename T>
constexpr auto
Unroll<1Z, 1Z, N, Bytes>::select(const ::simd::Unroll<1Z, 1Z, N, T> &x,
                                 const ::simd::Unroll<1Z, 1Z, N, T> &y)
  -> ::simd::Unroll<1Z, 1Z, N, T> {
  return {::simd::select(mask_, x.vec_, y.vec_)};
}
template <std::ptrdiff_t N, std::size_t Bytes>
template <typename T, std::ptrdiff_t C, std::ptrdiff_t W>
[[nodiscard]] TRIVIAL constexpr auto
Unroll<1Z, 1Z, N, Bytes>::select(const ::simd::Unroll<1Z, C, W, T> &x,
                                 const ::simd::Unroll<1Z, C, W, T> &y)
  -> ::simd::Unroll<1Z, C, W, T> requires((C * W == N) && (C != 1Z)) {
  static constexpr std::ptrdiff_t Nhalf = N >> 1;
  Unroll<1Z, 2Z, Nhalf, Bytes> s;
  auto splt = mask_.split();
  s.data_[0] = splt[0], s.data_[1] = splt[1];
  // either `s` matches, or continues the recursion
  return s.select(x, y);
}
} // namespace mask

#ifdef __AVX512F__

template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, 1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);
template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, 1L, 1UL, simd::mask::Bit<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);
template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, 1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<1L, 2L, 8L, long>
loadunroll<1L, 2L, 8L, long, 1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<1L, 3L, 8L, long>
loadunroll<1L, 3L, 8L, long, 1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<1L, 4L, 8L, long>
loadunroll<1L, 4L, 8L, long, 1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<2L, 2L, 8L, double>
loadunroll<2L, 2L, 8L, double, 1L, 1UL, simd::mask::None<8>>(
  const double *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<2L, 1L, 8L, double>
loadunroll<2L, 1L, 8L, double, -1L, 1UL, simd::mask::Bit<8>>(
  const double *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<2L, 1L, 8L, double>
loadunroll<2L, 1L, 8L, double, -1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const double *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<3L, 1L, 8L, double>
loadunroll<3L, 1L, 8L, double, -1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const double *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<4L, 1L, 8L, double>
loadunroll<4L, 1L, 8L, double, -1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const double *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<1L, 1L, 8L, double>
loadunroll<1L, 1L, 8L, double, 1L, 1UL, simd::mask::None<8>>(
  const double *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<1L, 4L, 8L, double>
loadunroll<1L, 4L, 8L, double, 1L, 1UL, simd::mask::None<8>>(
  const double *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<1L, 1L, 8L, double>
loadunroll<1L, 1L, 8L, double, 1L, 1UL, simd::mask::Bit<8>>(
  const double *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<1L, 1L, 8L, double>
loadunroll<1L, 1L, 8L, double, 1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const double *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<4L, 1L, 8L, long>
loadunroll<4L, 1L, 8L, long, -1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<4L, 1L, 8L, long>
loadunroll<4L, 1L, 8L, long, -1L, 1UL, simd::mask::Bit<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<1L, 4L, 8L, long>
loadunroll<1L, 4L, 8L, long, -1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, -1L, 1UL, simd::mask::Bit<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<3L, 1L, 8L, long>
loadunroll<3L, 1L, 8L, long, -1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<3L, 1L, 8L, long>
loadunroll<3L, 1L, 8L, long, -1L, 1UL, simd::mask::Bit<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<2L, 2L, 8L, long>
loadunroll<2L, 2L, 8L, long, -1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template Unroll<2L, 1L, 8L, long>
loadunroll<2L, 1L, 8L, long, -1L, 1UL, simd::mask::Bit<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::Bit<8>, 1UL> masks);

template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, -1L, 1UL, simd::mask::ExplicitLengthBit<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<8>, 1UL> masks);

template Unroll<1L, 1L, 4L, long>
loadunroll<1L, 1L, 4L, long, 1L, 1UL, simd::mask::ExplicitLengthBit<4>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::ExplicitLengthBit<4>, 1UL> masks);

template Unroll<1L, 1L, 4L, long>
loadunroll<1L, 1L, 4L, long, 1L, 1UL, simd::mask::None<4>>(
  const long *ptr, math::RowStride<1L> rowStride,
  std::array<simd::mask::None<4>, 1UL> masks);

template Unroll<1L, 1L, 8L, long>
loadunroll<1L, 1L, 8L, long, -1L, 1UL, simd::mask::None<8>>(
  const long *ptr, math::RowStride<-1L> rowStride,
  std::array<simd::mask::None<8>, 1UL> masks);

template auto index::unrollmask<1L, 4L>(std::ptrdiff_t L, std::ptrdiff_t i);
template auto index::unrollmask<1L, 8L>(std::ptrdiff_t L, std::ptrdiff_t i);
template auto index::unrollmask<2L, 8L>(std::ptrdiff_t L, std::ptrdiff_t i);
template auto index::unrollmask<3L, 8L>(std::ptrdiff_t L, std::ptrdiff_t i);

#endif

template <std::ptrdiff_t W, typename T>
TRIVIAL constexpr auto load(const T *p) {
  static constexpr std::ptrdiff_t L = simd::Width<T>;
  return simd::loadunroll<1, W / L, L>(p, math::RowStride<0>{}, {});
}

} // namespace simd
